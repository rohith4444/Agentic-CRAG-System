{"cells":[{"cell_type":"markdown","metadata":{"id":"ODAP5SmBAhen"},"source":["# **Project: Research Paper Answer Bot**"]},{"cell_type":"markdown","metadata":{"id":"SKa8XuuWBIdi"},"source":["## Installing all the dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"18i7Co5_BsGQ"},"outputs":[],"source":["!pip install langchain==0.2.0\n","!pip install langchain-openai==0.1.7\n","!pip install langchain-community==0.2.0\n","!pip install langgraph==0.1.1\n","\n","# takes 2 - 5 mins to install on Colab\n","!pip install \"unstructured[all-docs]==0.14.0\"\n","\n","!pip install jq==1.7.0\n","!pip install pypdf==4.2.0\n","!pip install pymupdf==1.24.4\n","\n","!pip install langchain-text-splitters==0.2.0\n","!pip install tiktoken==0.7.0\n","!pip install spacy\n","!pip install sentence-transformers==2.7.0\n","\n","!pip install langchain-huggingface==0.0.1\n","\n","!pip install langchain-chroma"]},{"cell_type":"markdown","metadata":{"id":"shgbNw94EsTk"},"source":["## Setup Key and Environmental Variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4gK7oM2ZErl3"},"outputs":[],"source":["from getpass import getpass\n","\n","OPENAI_KEY = getpass('Enter Open AI API Key: ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LsdOHLvyFB-2"},"outputs":[],"source":["HUGGINGFACEHUB_API_TOKEN = getpass('Enter HuggingFace Auth Token Key: ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mK-1WLzOrJdb"},"outputs":[],"source":["TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1JNp-qs2FMnR"},"outputs":[],"source":["import os\n","\n","os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n","os.environ['HUGGINGFACEHUB_API_TOKEN'] = HUGGINGFACEHUB_API_TOKEN\n","os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"]},{"cell_type":"markdown","metadata":{"id":"2oeckxFBcc0E"},"source":["## Load Connection to LLM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vHa9LMOfcOCV"},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","\n","chatgpt = ChatOpenAI(model_name='gpt-4o', temperature=0)"]},{"cell_type":"markdown","metadata":{"id":"FiNxag8-JiVg"},"source":["## **Implementing Compulsary Goals**"]},{"cell_type":"markdown","metadata":{"id":"tJdu06TZHEbQ"},"source":["### Load the Files and setup vector database"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mHBBV6FHDuma"},"outputs":[],"source":["from langchain_community.document_loaders import PyMuPDFLoader\n","\n","# Define a dictionary to map file extensions to their respective loaders\n","loaders = {\n","    '.pdf': (PyMuPDFLoader, {}),\n","    # '.docx': (UnstructuredWordDocumentLoader, {'strategy': 'fast',\n","    #                                           'chunking_strategy' : 'by_title',\n","    #                                           'max_characters' : 3000, # max limit of a document chunk\n","    #                                           'new_after_n_chars' : 2500, # preferred document chunk size\n","    #                                           'mode' : 'elements'\n","    #                                           })\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FU_I4clnDupr"},"outputs":[],"source":["from langchain_community.document_loaders import DirectoryLoader\n","\n","# Define a function to create a DirectoryLoader for a specific file type\n","def create_directory_loader(file_type, directory_path):\n","    return DirectoryLoader(\n","        path=directory_path,\n","        glob=f\"**/*{file_type}\",\n","        loader_cls=loaders[file_type][0],\n","        loader_kwargs=loaders[file_type][1],\n","        show_progress=True\n","    )\n","\n","# Create DirectoryLoader instances for each file type\n","pdf_loader = create_directory_loader('.pdf', '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data')\n","# docx_loader = create_directory_loader('.docx', './')\n","\n","# Load the files\n","pdf_documents = pdf_loader.load()\n","# docx_documents = docx_loader.load()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"11PQ6QaPDusr"},"outputs":[],"source":["len(pdf_documents)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"mXCJN1SnDuve"},"outputs":[],"source":["pdf_documents[18]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KeBIB57gTwIf"},"outputs":[],"source":["type(pdf_documents)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y_cTw-rnY-eI"},"outputs":[],"source":["docs = pdf_documents"]},{"cell_type":"markdown","metadata":{"id":"yPjmN39-Nv1Y"},"source":["**Create LangChain Documents**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E9KThjCwN0Ez"},"outputs":[],"source":["from langchain.docstore.document import Document\n","\n","docs = [Document(page_content=doc.page_content,\n","                 metadata=doc.metadata) for doc in docs]"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"cFMT5Y0xN_PV"},"outputs":[],"source":["docs[:3]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ccGsE7JYOilo"},"outputs":[],"source":["len(docs)"]},{"cell_type":"markdown","metadata":{"id":"ZaSljqmlOFwm"},"source":["**Split larger documents into smaller chunks**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-f9rqPnROE82"},"outputs":[],"source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=300)\n","chunked_docs = splitter.split_documents(docs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cqqp0RdkOsrg"},"outputs":[],"source":["chunked_docs[:3]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q-1rG2xnOqcn"},"outputs":[],"source":["len(chunked_docs)"]},{"cell_type":"markdown","metadata":{"id":"1s0vesVjaRU9"},"source":["**Experiment with different embedding models**"]},{"cell_type":"markdown","metadata":{"id":"qMZSsnbYaRU-"},"source":["**openAI embeddings**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tc6-tyxsaRU-"},"outputs":[],"source":["from langchain_openai import OpenAIEmbeddings\n","\n","# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n","openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1do4GnTaRU_"},"outputs":[],"source":["# Extract the text content from each document\n","chunked_docs_texts = [chunked_docs.page_content for chunked_docs in chunked_docs]\n","\n","# Pass the extracted text content to the embedding model\n","embeddings = openai_embed_model.embed_documents(chunked_docs_texts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rvO1bTv6aRU_"},"outputs":[],"source":["len(embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IG5TOLIvaRU_"},"outputs":[],"source":["len(embeddings[10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_QyweDl6aRU_"},"outputs":[],"source":["print(embeddings[10])"]},{"cell_type":"markdown","metadata":{"id":"DYZco5zjaRU_"},"source":["**Open Source Embedding Models on HuggingFace**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDlEH_J3aRVA"},"outputs":[],"source":["from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n","\n","# check out model details here: https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1\n","model_name = \"mixedbread-ai/mxbai-embed-large-v1\"\n","\n","hf_embeddings = HuggingFaceEmbeddings(\n","    model_name=model_name,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4WDgFaUUaRVA"},"outputs":[],"source":["embeddings = hf_embeddings.embed_documents(chunked_docs_texts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cxbbyq4BaRVA"},"outputs":[],"source":["len(embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SBFRIRZ4aRVA"},"outputs":[],"source":["len(embeddings[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"tuxz5jiFaRVA"},"outputs":[],"source":["print(embeddings[0])"]},{"cell_type":"markdown","metadata":{"id":"-PnV9lAXZw9a"},"source":["**Create a Vector DB and persist on disk**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KZagoXUQPjye"},"outputs":[],"source":["!rm -rf \"/content/research_papers_db\" #replace path to db"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kRYfcrsHUxyZ"},"outputs":[],"source":["from langchain_chroma import Chroma\n","\n","# create vector DB of docs and embeddings - takes < 30s on Colab\n","chroma_db = Chroma.from_documents(documents=chunked_docs,\n","                                  collection_name='research_papers_chroma_db',\n","                                  embedding=openai_embed_model,\n","                                  # need to set the distance function to cosine else it uses euclidean by default\n","                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n","                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n","                                  persist_directory=\"/content/research_papers_db\")"]},{"cell_type":"markdown","metadata":{"id":"9ju_zBIj1Zsb"},"source":["**Load Vector DB from disk**\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNvj0dDH1WDg"},"outputs":[],"source":["# load from disk\n","research_papers_chroma_db = Chroma(persist_directory=\"/content/research_papers_db\",\n","                   collection_name='research_papers_chroma_db',\n","                   embedding_function=openai_embed_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NFC3uPqYop0a"},"outputs":[],"source":["research_papers_chroma_db"]},{"cell_type":"markdown","metadata":{"id":"UVpAn6nuQm5U"},"source":["### Experiment with different retrieval stratagies"]},{"cell_type":"markdown","metadata":{"id":"aIGjT4xQG02J"},"source":["**ContexualCompressionretriever**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zSRG6upbftaS"},"outputs":[],"source":["from langchain.retrievers.document_compressors import LLMChainFilter\n","from langchain.retrievers import ContextualCompressionRetriever"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8taCb8F5qHuZ"},"outputs":[],"source":["# simple cosine distance based retriever\n","similarity_retriever = research_papers_chroma_db.as_retriever(search_type=\"similarity\",\n","                                              search_kwargs={\"k\": 3})\n","\n","#  decides which of the initially retrieved documents to filter out and which ones to return\n","_filter = LLMChainFilter.from_llm(llm=chatgpt)\n","\n","# retrieves the documents similar to query and then applies the filter\n","compression_retriever = ContextualCompressionRetriever(\n","    base_compressor=_filter, base_retriever=similarity_retriever\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ErDmz2Hcqxom"},"outputs":[],"source":["query = \"What attention mechanisms were used in the Attention paper?\"\n","docs = compression_retriever.invoke(query)\n","docs"]},{"cell_type":"markdown","metadata":{"id":"ZK-koWtwG7o9"},"source":["**MultiQueryRetriever**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_5pYI7SEqxr_"},"outputs":[],"source":["from langchain.retrievers.multi_query import MultiQueryRetriever\n","# Set logging for the queries\n","import logging\n","\n","similarity_retriever = research_papers_chroma_db.as_retriever(search_type=\"similarity\",\n","                                              search_kwargs={\"k\": 3})\n","\n","mq_retriever = MultiQueryRetriever.from_llm(\n","    retriever=similarity_retriever, llm=chatgpt\n",")\n","\n","logging.basicConfig()\n","# so we can see what queries are generated by the LLM\n","logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LGUnctn7qxut"},"outputs":[],"source":["query = \"What attention mechanisms were used in the Attention paper?\"\n","docs = mq_retriever.invoke(query)\n","docs"]},{"cell_type":"markdown","metadata":{"id":"9YK8BBMBAU9o"},"source":["**Chained Retrieval Pipeline**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UgZ4eMFc2GgI"},"outputs":[],"source":["from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n","from langchain.retrievers.document_compressors import CrossEncoderReranker\n","\n","# Retriever 1 - simple cosine distance based retriever\n","similarity_retriever = research_papers_chroma_db.as_retriever(search_type=\"similarity\",\n","                                              search_kwargs={\"k\": 5})\n","\n","#  decides which of the initially retrieved documents to filter out and which ones to return\n","_filter = LLMChainFilter.from_llm(llm=chatgpt)\n","# Retriever 2 - retrieves the documents similar to query and then applies the filter\n","compressor_retriever = ContextualCompressionRetriever(\n","    base_compressor=_filter, base_retriever=similarity_retriever\n",")\n","\n","# download an open-source reranker model - BAAI/bge-reranker-v2-m3\n","reranker = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-large\")\n","reranker_compressor = CrossEncoderReranker(model=reranker, top_n=3)\n","# Retriever 3 - Uses a Reranker model to rerank retrieval results from the previous retriever\n","final_retriever = ContextualCompressionRetriever(\n","    base_compressor=reranker_compressor, base_retriever=compressor_retriever\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"8dVz4JGVBQTO"},"outputs":[],"source":["query = \"What attention mechanisms were used in the Attention paper?\"\n","docs = final_retriever.invoke(query)\n","docs"]},{"cell_type":"markdown","metadata":{"id":"Bfn4Z4Em55bb"},"source":["### QA RAG System\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Pu5U9HNkl-q"},"outputs":[],"source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","prompt = \"\"\"You are an assistant for question-answering tasks.\n","            Use the following pieces of retrieved context to answer the question.\n","            If no context is present or if you don't know the answer, just say that you don't know.\n","            Do not make up the answer unless it is there in the provided context.\n","            Give a detailed answer with regard to the question.\n","\n","            Question:\n","            {question}\n","\n","            Context:\n","            {context}\n","\n","            Answer:\n","         \"\"\"\n","\n","prompt_template = ChatPromptTemplate.from_template(prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"18p2bJahmLX_"},"outputs":[],"source":["from langchain_core.runnables import RunnablePassthrough\n","\n","def format_docs(docs):\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)\n","\n","qa_rag_chain = (\n","    {\n","        \"context\": (final_retriever\n","                      |\n","                    format_docs),\n","        \"question\": RunnablePassthrough()\n","    }\n","      |\n","    prompt_template\n","      |\n","    chatgpt\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W2Ion52G99-A"},"outputs":[],"source":["from IPython.display import Markdown, display\n","\n","# Helper function to display answer and sources\n","def display_answer_with_sources(query):\n","    # Run the RAG chain and get the result\n","    result = qa_rag_chain.invoke(query)\n","\n","    # Retrieve the top 3 context documents (the sources)\n","    top_docs = final_retriever.invoke(query)[:3]  # Limit to top 3\n","    sources = format_docs(top_docs)\n","\n","    # Display the generated answer\n","    display(Markdown(f\"### Answer:\\n{result.content}\"))\n","\n","    # Display the sources\n","    display(Markdown(\"### Sources (Top 3 Retrieved Documents):\"))\n","    display(Markdown(sources))\n","\n","# Test query: attention mechanisms in the Attention paper\n","query = \"What attention mechanisms were used in the Attention paper?\"\n","display_answer_with_sources(query)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hdYPx4g39wpW"},"outputs":[],"source":["query = \"What novel approaches did the Gemini paper introduce in LLM training?\"\n","display_answer_with_sources(query)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QJrm6LeOnTU5"},"outputs":[],"source":["query = \"What datasets were used for training in the GPT-4 paper?\"\n","display_answer_with_sources(query)"]},{"cell_type":"markdown","metadata":{"id":"xEtBJSZLJCmC"},"source":["## **Implementing Stretch Goal: Advanced Option 3**"]},{"cell_type":"markdown","metadata":{"id":"RXeilff0c9X5"},"source":["### Create a Query Retrieval Grader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ubFlSqlMSU99"},"outputs":[],"source":["from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain_openai import ChatOpenAI\n","\n","\n","# Data model for LLM output format\n","class GradeDocuments(BaseModel):\n","    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n","    binary_score: str = Field(\n","        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n","    )\n","\n","\n","# LLM for grading\n","llm = chatgpt\n","structured_llm_grader = llm.with_structured_output(GradeDocuments)\n","\n","# Prompt template for grading\n","SYS_PROMPT = \"\"\"You are an expert grader assessing relevance of a retrieved document to a user question.\n","                Follow these instructions for grading:\n","                  - If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n","                  - Your grade should be either 'yes' or 'no' to indicate whether the document is relevant to the question or not.\n","             \"\"\"\n","grade_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", SYS_PROMPT),\n","        (\"human\", \"\"\"Retrieved document:\n","                     {document}\n","\n","                     User question:\n","                     {question}\n","                  \"\"\"),\n","    ]\n",")\n","\n","# Build grader chain\n","doc_grader = (grade_prompt\n","                  |\n","              structured_llm_grader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UuiAlPIbaC0W"},"outputs":[],"source":["query = \"What attention mechanisms were used in the Attention paper?\"\n","top3_docs = final_retriever.invoke(query)\n","for doc in top3_docs:\n","    print(doc.page_content)\n","    print('GRADE:', doc_grader.invoke({\"question\": query, \"document\": doc.page_content}))\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"4PpFmwNFZ3lt"},"source":["### Build a QA RAG Chain"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M2uXFNdbZ3mD"},"outputs":[],"source":["from langchain_core.prompts import ChatPromptTemplate\n","from langchain_openai import ChatOpenAI\n","from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n","from langchain_core.output_parsers import StrOutputParser\n","from operator import itemgetter\n","\n","prompt = \"\"\"You are an assistant for question-answering tasks.\n","            Use the following pieces of retrieved context to answer the question.\n","            If no context is present or if you don't know the answer, just say that you don't know the answer.\n","            Do not make up the answer unless it is there in the provided context.\n","            However, if there are any web search results, always consider them in your response.\n","            Give a detailed answer and to the point answer with regard to the question.\n","\n","            Question:\n","            {question}\n","\n","            Context:\n","            {context}\n","\n","            Answer:\n","         \"\"\"\n","prompt_template = ChatPromptTemplate.from_template(prompt)\n","\n","def format_docs(docs):\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)\n","\n","qa_rag_chain = (\n","    {\n","        \"context\": (itemgetter('context')\n","                        |\n","                    RunnableLambda(format_docs)),\n","        \"question\": itemgetter('question')\n","    }\n","      |\n","    prompt_template\n","      |\n","    chatgpt\n","      |\n","    StrOutputParser()\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Wj-MZr2eEq8"},"outputs":[],"source":["query = \"What attention mechanisms were used in the Attention paper?\"\n","top3_docs = final_retriever.invoke(query)\n","result = qa_rag_chain.invoke(\n","    {\"context\": top3_docs, \"question\": query}\n",")\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"-Fp8Eh0x5bMY"},"source":["### Create a Query Rephraser"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mm7T22tmfYWj"},"outputs":[],"source":["# Prompt template for rewriting\n","SYS_PROMPT = \"\"\"Act as a question re-writer and perform the following task:\n","                 - Convert the following input question to a better version that is optimized for web search.\n","                 - When re-writing, look at the input question and try to reason about the underlying semantic intent / meaning.\n","             \"\"\"\n","re_write_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", SYS_PROMPT),\n","        (\"human\", \"\"\"Here is the initial question:\n","                     {question}\n","\n","                     Formulate an improved question.\n","                  \"\"\",\n","        ),\n","    ]\n",")\n","\n","question_rewriter = (re_write_prompt\n","                        |\n","                       chatgpt\n","                        |\n","                     StrOutputParser())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2bGCpLKzhTUr"},"outputs":[],"source":["query = \"What attention mechanisms were used in the Attention paper?\"\n","question_rewriter.invoke({\"question\": query})"]},{"cell_type":"markdown","metadata":{"id":"howf-v0ARWbv"},"source":["### Load Web Search Tool"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ue8xgu9WpuPi"},"outputs":[],"source":["from langchain_community.tools.tavily_search import TavilySearchResults\n","\n","tv_search = TavilySearchResults(max_results=3, search_depth='advanced',\n","                                max_tokens=10000)"]},{"cell_type":"markdown","metadata":{"id":"D2N5192vikJR"},"source":["### Build Agentic RAG components\n","\n","Here we will build the key components of our Agentic Corrective RAG System as per the workflow below:\n","\n","![](https://i.imgur.com/uhybMhT.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U5tUXzqPsbQi"},"source":["### Graph State\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_B2EFrwTpuXB"},"outputs":[],"source":["from typing import List\n","from typing_extensions import TypedDict\n","\n","class GraphState(TypedDict):\n","    \"\"\"\n","    Represents the state of our graph.\n","\n","    Attributes:\n","        question: question\n","        generation: LLM response generation\n","        web_search_needed: flag of whether to add web search - yes or no\n","        documents: list of context documents\n","    \"\"\"\n","\n","    question: str\n","    generation: str\n","    web_search_needed: str\n","    documents: List[str]"]},{"cell_type":"markdown","metadata":{"id":"qXfVLhOWtHJJ"},"source":["### Retrieve function for retrieval from Vector DB"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W0rVVBGDpuYw"},"outputs":[],"source":["def retrieve(state):\n","    \"\"\"\n","    Retrieve documents\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): New key added to state, documents - that contains retrieved context documents\n","    \"\"\"\n","    print(\"---RETRIEVAL FROM VECTOR DB---\")\n","    question = state[\"question\"]\n","\n","    # Retrieval\n","    documents = final_retriever.invoke(question)\n","    return {\"documents\": documents, \"question\": question}"]},{"cell_type":"markdown","metadata":{"id":"lpOsUnzn6Yo1"},"source":["### Grade documents"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NI20nh1DtTwJ"},"outputs":[],"source":["def grade_documents(state):\n","    \"\"\"\n","    Determines whether the retrieved documents are relevant to the question\n","    by using an LLM Grader.\n","\n","    If any document are not relevant to question or documents are empty - Web Search needs to be done\n","    If all documents are relevant to question - Web Search is not needed\n","    Helps filtering out irrelevant documents\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): Updates documents key with only filtered relevant documents\n","    \"\"\"\n","\n","    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","\n","    # Score each doc\n","    filtered_docs = []\n","    web_search_needed = \"Yes\"\n","    if documents:\n","        for d in documents:\n","            score = doc_grader.invoke(\n","                {\"question\": question, \"document\": d.page_content}\n","            )\n","            grade = score.binary_score\n","            if grade == \"yes\":\n","                print(\"---GRADE: DOCUMENT RELEVANT---\")\n","                filtered_docs.append(d)\n","                web_search_needed = \"No\"\n","            else:\n","                print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n","    else:\n","        print(\"---NO DOCUMENTS RETRIEVED---\")\n","\n","    return {\"documents\": filtered_docs, \"question\": question, \"web_search_needed\": web_search_needed}"]},{"cell_type":"markdown","metadata":{"id":"fj1jk8C16hhE"},"source":["### Rewrite query"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xw_iVhvWuSG-"},"outputs":[],"source":["def rewrite_query(state):\n","    \"\"\"\n","    Rewrite the query to produce a better question.\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): Updates question key with a re-phrased or re-written question\n","    \"\"\"\n","\n","    print(\"---REWRITE QUERY---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","\n","    # Re-write question\n","    better_question = question_rewriter.invoke({\"question\": question})\n","    return {\"documents\": documents, \"question\": better_question}"]},{"cell_type":"markdown","metadata":{"id":"HMogEnhT7Icn"},"source":["### Web Search"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YM7f6AyCvUP_"},"outputs":[],"source":["from langchain.schema import Document\n","\n","def web_search(state):\n","    \"\"\"\n","    Web search based on the re-written question.\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): Updates documents key with appended web results\n","    \"\"\"\n","\n","    print(\"---WEB SEARCH---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","\n","    # Web search\n","    docs = tv_search.invoke(question)\n","    print(\"---WEB SEARCH RESULTS---\")\n","    for doc in docs:\n","        print(doc[\"content\"])\n","\n","    for d in docs:\n","        documents.append(Document(page_content=d[\"content\"]))\n","\n","    # web_results = \"\\n\\n\".join([d[\"content\"] for d in docs])\n","    # web_results = Document(page_content=web_results)\n","    # documents.append(web_results)\n","\n","    return {\"documents\": documents, \"question\": question}"]},{"cell_type":"markdown","metadata":{"id":"ruTBxSkm7R2R"},"source":["### Generate Answer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MemqMTolwLhA"},"outputs":[],"source":["def generate_answer(state):\n","    \"\"\"\n","    Generate answer from context document using LLM\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): New key added to state, generation, that contains LLM generation\n","    \"\"\"\n","    print(\"---GENERATE ANSWER---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","\n","    # Ensure there is context before attempting to generate an answer\n","    if documents:\n","        generation = qa_rag_chain.invoke({\"context\": documents, \"question\": question})\n","    else:\n","        generation = \"I don't know the answer. The context provided does not contain information to answer the question.\"\n","\n","    return {\"documents\": documents, \"question\": question, \"generation\": generation}"]},{"cell_type":"markdown","metadata":{"id":"-9zcEgiu8HRY"},"source":["### Decide to Generate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zi3GzDLRv3Nf"},"outputs":[],"source":["def decide_to_generate(state):\n","    \"\"\"\n","    Determines whether to generate an answer, or re-generate a question.\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        str: Binary decision for next node to call\n","    \"\"\"\n","\n","    print(\"---ASSESS GRADED DOCUMENTS---\")\n","    web_search_needed = state[\"web_search_needed\"]\n","\n","    if web_search_needed == \"Yes\":\n","        # All documents have been filtered check_relevance\n","        # We will re-generate a new query\n","        print(\"---DECISION: SOME or ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, REWRITE QUERY---\")\n","        return \"rewrite_query\"\n","    else:\n","        # We have relevant documents, so generate answer\n","        print(\"---DECISION: GENERATE RESPONSE---\")\n","        return \"generate_answer\""]},{"cell_type":"markdown","metadata":{"id":"EpjPx4v89BVV"},"source":["### Build the Agent Graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F24b6qm_yhnE"},"outputs":[],"source":["from langgraph.graph import END, StateGraph\n","\n","agentic_rag = StateGraph(GraphState)\n","\n","# Define the nodes\n","agentic_rag.add_node(\"retrieve\", retrieve)  # retrieve\n","agentic_rag.add_node(\"grade_documents\", grade_documents)  # grade documents\n","agentic_rag.add_node(\"rewrite_query\", rewrite_query)  # transform_query\n","agentic_rag.add_node(\"web_search\", web_search)  # web search\n","agentic_rag.add_node(\"generate_answer\", generate_answer)  # generate answer\n","\n","# Build graph\n","agentic_rag.set_entry_point(\"retrieve\")\n","agentic_rag.add_edge(\"retrieve\", \"grade_documents\")\n","agentic_rag.add_conditional_edges(\n","    \"grade_documents\",\n","    decide_to_generate,\n","    {\"rewrite_query\": \"rewrite_query\", \"generate_answer\": \"generate_answer\"},\n",")\n","agentic_rag.add_edge(\"rewrite_query\", \"web_search\")\n","agentic_rag.add_edge(\"web_search\", \"generate_answer\")\n","agentic_rag.add_edge(\"generate_answer\", END)\n","\n","# Compile\n","agentic_rag = agentic_rag.compile()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o7s8SElUvnHD"},"outputs":[],"source":["from IPython.display import Image, display, Markdown\n","\n","display(Image(agentic_rag.get_graph().draw_mermaid_png()))"]},{"cell_type":"markdown","metadata":{"id":"pXW3yX7s9MMY"},"source":["### Test the Agentic CRAG System"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tgny4kCM0OrS"},"outputs":[],"source":["query = \"What attention mechanisms were used in the Attention paper?\"\n","response = agentic_rag.invoke({\"question\": query})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Y7Q-KAF2oqA"},"outputs":[],"source":["display(Markdown(response['generation']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oVSzCfgb0q4q"},"outputs":[],"source":["response"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aAm5ERMM2fFL"},"outputs":[],"source":["query = \"What novel approaches did the Gemini paper introduce in LLM training?\"\n","response = agentic_rag.invoke({\"question\": query})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CTCcEfNx2w-5"},"outputs":[],"source":["display(Markdown(response['generation']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0PH45g2E3Dta"},"outputs":[],"source":["query = \"What datasets were used for training in the GPT-4 paper?\"\n","response = agentic_rag.invoke({\"question\": query})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6G7ywp53FrO"},"outputs":[],"source":["display(Markdown(response['generation']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GT3fGcmbvnjo"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true,"mount_file_id":"1Uzu_tZSoXPbhyWQ6_Y5umCNW__rIh4pK","authorship_tag":"ABX9TyNtXQ72haxHr5RZH/x6/u7p"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}