{"cells":[{"cell_type":"markdown","metadata":{"id":"ODAP5SmBAhen"},"source":["# **Project: Research Paper Answer Bot**"]},{"cell_type":"markdown","metadata":{"id":"SKa8XuuWBIdi"},"source":["## Installing all the dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":66771,"status":"ok","timestamp":1729979646178,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"18i7Co5_BsGQ","outputId":"b473cfbd-0ad2-43e2-e3fb-b7f8c82b9469"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain==0.2.0 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (2.0.36)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (3.10.10)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (4.0.3)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (0.6.7)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (0.2.41)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (0.2.4)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (0.1.137)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (1.26.4)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (2.9.2)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (2.32.3)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.0) (8.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.16.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0) (3.23.0)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0) (0.9.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (3.10.10)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.2.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.2.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.2.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.2.0) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.0) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.0.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (3.0.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.2.0) (1.0.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (0.2.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.2.2)\n","Requirement already satisfied: langchain-openai==0.1.7 in /usr/local/lib/python3.10/dist-packages (0.1.7)\n","Requirement already satisfied: langchain-core<0.3,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.7) (0.2.41)\n","Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.7) (1.52.2)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.7) (0.8.0)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (0.1.137)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (24.1)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (2.9.2)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (8.5.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (4.12.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (0.27.2)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (0.6.1)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (4.66.5)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.1.7) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.1.7) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (3.10)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (1.0.6)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.7) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (3.10.10)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-openai==0.1.7) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.1.7) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.1.7) (2.2.3)\n","Requirement already satisfied: langchain-community==0.2.0 in /usr/local/lib/python3.10/dist-packages (0.2.0)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (2.0.36)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (3.10.10)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (0.6.7)\n","Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (0.2.0)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (0.2.41)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (0.1.137)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (1.26.4)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (2.32.3)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.0) (8.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.16.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (4.0.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (3.23.0)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (0.2.4)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (2.9.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (3.10.10)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.2.0) (3.1.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.0.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (2.23.4)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (1.0.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (0.2.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.2.2)\n","Requirement already satisfied: langgraph==0.1.1 in /usr/local/lib/python3.10/dist-packages (0.1.1)\n","Requirement already satisfied: langchain-core<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from langgraph==0.1.1) (0.2.41)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.1.137)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (24.1)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.9.2)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (8.5.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langgraph==0.1.1) (4.12.2)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.10.10)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.32.3)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.23.4)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.0.6)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (0.14.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (2.2.3)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.2->langgraph==0.1.1) (1.2.2)\n","Requirement already satisfied: unstructured==0.14.0 in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (0.14.0)\n","Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (5.2.0)\n","Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.2.0)\n","Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.4.27)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (4.9.4)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (3.8.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2.32.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (4.12.3)\n","Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2.14.0)\n","Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.6.7)\n","Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2024.10.22)\n","Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.0.9)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.26.4)\n","Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (3.10.1)\n","Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2.2.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (4.12.2)\n","Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.26.1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.16.0)\n","Requirement already satisfied: pikepdf in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (9.3.0)\n","Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (20231228)\n","Requirement already satisfied: python-pptx<=0.6.23 in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (0.6.23)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (3.4.2)\n","Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (1.17.0)\n","Requirement already satisfied: pypandoc in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (1.14)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (1.17.0)\n","Requirement already satisfied: unstructured.pytesseract>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (0.3.13)\n","Requirement already satisfied: google-cloud-vision in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (3.8.0)\n","Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (1.1.2)\n","Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (5.0.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (2.2.2)\n","Requirement already satisfied: pillow-heif in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (0.20.0)\n","Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (3.7)\n","Requirement already satisfied: msg-parser in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (1.2.0)\n","Requirement already satisfied: unstructured-inference==0.7.31 in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (0.7.31)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (3.1.5)\n","Requirement already satisfied: xlrd in /usr/local/lib/python3.10/dist-packages (from unstructured[all-docs]==0.14.0) (2.0.1)\n","Requirement already satisfied: layoutparser[layoutmodels,tesseract] in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.3.4)\n","Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.0.12)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.24.7)\n","Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (4.10.0.84)\n","Requirement already satisfied: onnxruntime>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (1.19.2)\n","Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (4.44.2)\n","Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from python-pptx<=0.6.23->unstructured[all-docs]==0.14.0) (10.4.0)\n","Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from python-pptx<=0.6.23->unstructured[all-docs]==0.14.0) (3.2.0)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from unstructured.pytesseract>=0.3.12->unstructured[all-docs]==0.14.0) (24.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2.6)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (3.23.0)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.9.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (2.19.2)\n","Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[all-docs]==0.14.0) (2.27.0)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[all-docs]==0.14.0) (1.24.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-vision->unstructured[all-docs]==0.14.0) (3.20.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.16.0)\n","Requirement already satisfied: olefile>=0.46 in /usr/local/lib/python3.10/dist-packages (from msg-parser->unstructured[all-docs]==0.14.0) (0.47)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (4.66.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->unstructured[all-docs]==0.14.0) (1.1.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured[all-docs]==0.14.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured[all-docs]==0.14.0) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->unstructured[all-docs]==0.14.0) (2024.2)\n","Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[all-docs]==0.14.0) (3.4.0)\n","Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[all-docs]==0.14.0) (43.0.3)\n","Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from pikepdf->unstructured[all-docs]==0.14.0) (1.2.14)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2024.8.30)\n","Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.2.0)\n","Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.27.2)\n","Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.0.6)\n","Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.6.0)\n","Requirement already satisfied: pydantic<2.10.0,>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2.9.2)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.0.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]==0.14.0) (1.17.1)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (1.65.0)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (1.64.1)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (1.48.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (4.9)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.0.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.14.0)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (24.3.25)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (1.13.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.9.0->unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.10.0,>=2.9.0->unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (2.23.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (3.16.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (6.0.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.19.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (2024.6.1)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.0.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (1.13.1)\n","Requirement already satisfied: iopath in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.1.10)\n","Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.11.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (2.5.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.20.0+cu121)\n","Requirement already satisfied: effdet in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.4.1)\n","Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.3.13)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[all-docs]==0.14.0) (2.22)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[all-docs]==0.14.0) (0.6.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured==0.14.0->unstructured[all-docs]==0.14.0) (1.2.2)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (10.0)\n","Requirement already satisfied: timm>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (1.0.11)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (2.0.8)\n","Requirement already satisfied: omegaconf>=2.0 in /usr/local/lib/python3.10/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (2.3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (3.1.4)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (1.3.0)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (2.10.1)\n","Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (4.30.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (4.9.3)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (3.7.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (3.0.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.31->unstructured[all-docs]==0.14.0) (3.2.0)\n","Requirement already satisfied: jq==1.7.0 in /usr/local/lib/python3.10/dist-packages (1.7.0)\n","Collecting pypdf==4.2.0\n","  Using cached pypdf-4.2.0-py3-none-any.whl.metadata (7.4 kB)\n","Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf==4.2.0) (4.12.2)\n","Using cached pypdf-4.2.0-py3-none-any.whl (290 kB)\n","Installing collected packages: pypdf\n","  Attempting uninstall: pypdf\n","    Found existing installation: pypdf 5.0.1\n","    Uninstalling pypdf-5.0.1:\n","      Successfully uninstalled pypdf-5.0.1\n","Successfully installed pypdf-4.2.0\n","Requirement already satisfied: pymupdf==1.24.4 in /usr/local/lib/python3.10/dist-packages (1.24.4)\n","Requirement already satisfied: PyMuPDFb==1.24.3 in /usr/local/lib/python3.10/dist-packages (from pymupdf==1.24.4) (1.24.3)\n","Collecting langchain-text-splitters==0.2.0\n","  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-text-splitters==0.2.0) (0.2.41)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (0.1.137)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (24.1)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (2.9.2)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (8.5.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (4.12.2)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (3.10.10)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (2.32.3)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (2.23.4)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (1.0.6)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (3.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (0.14.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (3.4.0)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.112->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (2.2.3)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.0) (1.2.2)\n","Downloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n","Installing collected packages: langchain-text-splitters\n","  Attempting uninstall: langchain-text-splitters\n","    Found existing installation: langchain-text-splitters 0.2.4\n","    Uninstalling langchain-text-splitters-0.2.4:\n","      Successfully uninstalled langchain-text-splitters-0.2.4\n","Successfully installed langchain-text-splitters-0.2.0\n","Collecting tiktoken==0.7.0\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.7.0) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.7.0) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.7.0) (2024.8.30)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tiktoken\n","  Attempting uninstall: tiktoken\n","    Found existing installation: tiktoken 0.8.0\n","    Uninstalling tiktoken-0.8.0:\n","      Successfully uninstalled tiktoken-0.8.0\n","Successfully installed tiktoken-0.7.0\n","Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.3)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","Collecting sentence-transformers==2.7.0\n","  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0) (4.44.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0) (4.66.5)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0) (2.5.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0) (1.5.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0) (1.13.1)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0) (0.24.7)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0) (10.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.7.0) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.7.0) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.7.0) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.7.0) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.7.0) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.7.0) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers==2.7.0) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers==2.7.0) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers==2.7.0) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers==2.7.0) (0.19.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.7.0) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.7.0) (3.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==2.7.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.7.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.7.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.7.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers==2.7.0) (2024.8.30)\n","Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentence-transformers\n","Successfully installed sentence-transformers-2.7.0\n","Collecting langchain-huggingface==0.0.1\n","  Downloading langchain_huggingface-0.0.1-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface==0.0.1) (0.24.7)\n","Requirement already satisfied: langchain-core<0.3,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface==0.0.1) (0.2.41)\n","Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface==0.0.1) (2.7.0)\n","Collecting text-generation<0.8.0,>=0.7.0 (from langchain-huggingface==0.0.1)\n","  Downloading text_generation-0.7.0-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface==0.0.1) (0.19.1)\n","Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface==0.0.1) (4.44.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.0.1) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.0.1) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.0.1) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.0.1) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.0.1) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.0.1) (4.66.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface==0.0.1) (4.12.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface==0.0.1) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface==0.0.1) (0.1.137)\n","Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface==0.0.1) (2.9.2)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface==0.0.1) (8.5.0)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.0.1) (2.5.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.0.1) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.0.1) (1.5.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.0.1) (1.13.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface==0.0.1) (10.4.0)\n","Requirement already satisfied: aiohttp<4.0,>=3.8 in /usr/local/lib/python3.10/dist-packages (from text-generation<0.8.0,>=0.7.0->langchain-huggingface==0.0.1) (3.10.10)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface==0.0.1) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface==0.0.1) (0.4.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->text-generation<0.8.0,>=0.7.0->langchain-huggingface==0.0.1) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->text-generation<0.8.0,>=0.7.0->langchain-huggingface==0.0.1) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->text-generation<0.8.0,>=0.7.0->langchain-huggingface==0.0.1) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->text-generation<0.8.0,>=0.7.0->langchain-huggingface==0.0.1) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->text-generation<0.8.0,>=0.7.0->langchain-huggingface==0.0.1) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->text-generation<0.8.0,>=0.7.0->langchain-huggingface==0.0.1) (1.16.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.8->text-generation<0.8.0,>=0.7.0->langchain-huggingface==0.0.1) (4.0.3)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain-huggingface==0.0.1) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain-huggingface==0.0.1) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain-huggingface==0.0.1) (3.10.10)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain-huggingface==0.0.1) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-huggingface==0.0.1) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-huggingface==0.0.1) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface==0.0.1) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface==0.0.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface==0.0.1) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface==0.0.1) (2024.8.30)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.0.1) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.0.1) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.0.1) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.0.1) (1.3.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface==0.0.1) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface==0.0.1) (3.5.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain-huggingface==0.0.1) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain-huggingface==0.0.1) (1.0.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain-huggingface==0.0.1) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain-huggingface==0.0.1) (0.14.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0,>=3.8->text-generation<0.8.0,>=0.7.0->langchain-huggingface==0.0.1) (0.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.0.1) (3.0.2)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain-huggingface==0.0.1) (1.2.2)\n","Downloading langchain_huggingface-0.0.1-py3-none-any.whl (17 kB)\n","Downloading text_generation-0.7.0-py3-none-any.whl (12 kB)\n","Installing collected packages: text-generation, langchain-huggingface\n","Successfully installed langchain-huggingface-0.0.1 text-generation-0.7.0\n","Collecting langchain-chroma\n","  Downloading langchain_chroma-0.1.4-py3-none-any.whl.metadata (1.6 kB)\n","Collecting chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 (from langchain-chroma)\n","  Downloading chromadb-0.5.15-py3-none-any.whl.metadata (6.8 kB)\n","Collecting fastapi<1,>=0.95.2 (from langchain-chroma)\n","  Downloading fastapi-0.115.3-py3-none-any.whl.metadata (27 kB)\n","Requirement already satisfied: langchain-core<0.4,>=0.1.40 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.2.41)\n","Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (1.26.4)\n","Collecting build>=1.0.3 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.9.2)\n","Collecting chroma-hnswlib==0.7.6 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n","Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n","Collecting posthog>=2.4.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.12.2)\n","Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.19.2)\n","Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n","Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n","Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n","Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.19.1)\n","Collecting pypika>=0.48.9 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.66.5)\n","Collecting overrides>=7.3.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.4.5)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.64.1)\n","Collecting bcrypt>=4.0.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n","Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.12.5)\n","Collecting kubernetes>=28.1.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.5.0)\n","Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.0.2)\n","Collecting mmh3>=4.0.1 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n","Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10.10)\n","Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.27.2)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.9.3)\n","Collecting starlette<0.42.0,>=0.40.0 (from fastapi<1,>=0.95.2->langchain-chroma)\n","  Downloading starlette-0.41.0-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.1.40->langchain-chroma) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.1.40->langchain-chroma) (0.1.137)\n","Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.1.40->langchain-chroma) (24.1)\n","Collecting pyproject_hooks (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.0.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.6)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1.40->langchain-chroma) (3.0.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.8.2)\n","Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.27.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.32.3)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n","Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n","Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.3)\n","Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.4,>=0.1.40->langchain-chroma) (1.0.0)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.13.1)\n","Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.14)\n","Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (75.1.0)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.65.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n","Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-sdk>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n","Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n","Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.16.0)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n","Collecting opentelemetry-api>=1.2.0 (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n","Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n","Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.23.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.24.7)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\n","Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma)\n","  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2024.6.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.20.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.4.0)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (10.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\n","Downloading langchain_chroma-0.1.4-py3-none-any.whl (10 kB)\n","Downloading chromadb-0.5.15-py3-none-any.whl (607 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m607.0/607.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastapi-0.115.3-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n","Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n","Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n","Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n","Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n","Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n","Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Downloading posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading starlette-0.41.0-py3-none-any.whl (73 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n","Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n","Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n","Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n","Building wheels for collected packages: pypika\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=2ace57647af7f8192032d09743da5750d1772b39b43988387dfa6ef69350f68b\n","  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n","Successfully built pypika\n","Installing collected packages: pypika, monotonic, durationpy, websockets, uvloop, uvicorn, python-dotenv, pyproject_hooks, overrides, opentelemetry-util-http, opentelemetry-proto, mmh3, importlib-metadata, httptools, chroma-hnswlib, bcrypt, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, build, opentelemetry-semantic-conventions, opentelemetry-instrumentation, kubernetes, fastapi, opentelemetry-sdk, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, chromadb, langchain-chroma\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib_metadata 8.5.0\n","    Uninstalling importlib_metadata-8.5.0:\n","      Successfully uninstalled importlib_metadata-8.5.0\n","  Attempting uninstall: opentelemetry-api\n","    Found existing installation: opentelemetry-api 1.16.0\n","    Uninstalling opentelemetry-api-1.16.0:\n","      Successfully uninstalled opentelemetry-api-1.16.0\n","  Attempting uninstall: opentelemetry-semantic-conventions\n","    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n","    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n","      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n","  Attempting uninstall: opentelemetry-sdk\n","    Found existing installation: opentelemetry-sdk 1.16.0\n","    Uninstalling opentelemetry-sdk-1.16.0:\n","      Successfully uninstalled opentelemetry-sdk-1.16.0\n","Successfully installed asgiref-3.8.1 bcrypt-4.2.0 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.15 durationpy-0.9 fastapi-0.115.3 httptools-0.6.4 importlib-metadata-8.4.0 kubernetes-31.0.0 langchain-chroma-0.1.4 mmh3-5.0.1 monotonic-1.6 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 overrides-7.7.0 posthog-3.7.0 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 starlette-0.41.0 uvicorn-0.32.0 uvloop-0.21.0 watchfiles-0.24.0 websockets-13.1\n"]}],"source":["!pip install langchain==0.2.0\n","!pip install langchain-openai==0.1.7\n","!pip install langchain-community==0.2.0\n","!pip install langgraph==0.1.1\n","\n","# takes 2 - 5 mins to install on Colab\n","!pip install \"unstructured[all-docs]==0.14.0\"\n","\n","!pip install jq==1.7.0\n","!pip install pypdf==4.2.0\n","!pip install pymupdf==1.24.4\n","\n","!pip install langchain-text-splitters==0.2.0\n","!pip install tiktoken==0.7.0\n","!pip install spacy\n","!pip install sentence-transformers==2.7.0\n","\n","!pip install langchain-huggingface==0.0.1\n","\n","!pip install langchain-chroma"]},{"cell_type":"markdown","metadata":{"id":"shgbNw94EsTk"},"source":["## Setup Key and Environmental Variables"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12432,"status":"ok","timestamp":1729979669425,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"4gK7oM2ZErl3","outputId":"800303e8-0a99-43ae-813c-ce324b1250dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter Open AI API Key: \n"]}],"source":["from getpass import getpass\n","\n","OPENAI_KEY = getpass('Enter Open AI API Key: ')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12887,"status":"ok","timestamp":1729979684980,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"LsdOHLvyFB-2","outputId":"7d364862-3948-4340-d7eb-84fa19aa13ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter HuggingFace Auth Token Key: \n"]}],"source":["HUGGINGFACEHUB_API_TOKEN = getpass('Enter HuggingFace Auth Token Key: ')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9026,"status":"ok","timestamp":1729979696035,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"mK-1WLzOrJdb","outputId":"2a150116-e01b-439b-e564-a7045e4f6fe6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter Tavily Search API Key: \n"]}],"source":["TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":169,"status":"ok","timestamp":1729979700759,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"1JNp-qs2FMnR"},"outputs":[],"source":["import os\n","\n","os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n","os.environ['HUGGINGFACEHUB_API_TOKEN'] = HUGGINGFACEHUB_API_TOKEN\n","os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"]},{"cell_type":"markdown","metadata":{"id":"2oeckxFBcc0E"},"source":["## Load Connection to LLM"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1604,"status":"ok","timestamp":1729979702541,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"vHa9LMOfcOCV"},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","\n","chatgpt = ChatOpenAI(model_name='gpt-4o', temperature=0)"]},{"cell_type":"markdown","metadata":{"id":"FiNxag8-JiVg"},"source":["## **Implementing Compulsary Goals**"]},{"cell_type":"markdown","metadata":{"id":"tJdu06TZHEbQ"},"source":["### Load the Files and setup vector database"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1729979702541,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"mHBBV6FHDuma"},"outputs":[],"source":["from langchain_community.document_loaders import PyMuPDFLoader\n","\n","# Define a dictionary to map file extensions to their respective loaders\n","loaders = {\n","    '.pdf': (PyMuPDFLoader, {}),\n","    # '.docx': (UnstructuredWordDocumentLoader, {'strategy': 'fast',\n","    #                                           'chunking_strategy' : 'by_title',\n","    #                                           'max_characters' : 3000, # max limit of a document chunk\n","    #                                           'new_after_n_chars' : 2500, # preferred document chunk size\n","    #                                           'mode' : 'elements'\n","    #                                           })\n","}"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3091,"status":"ok","timestamp":1729979705630,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"FU_I4clnDupr","outputId":"bdb8ff22-d999-4e20-e482-fdab2b6d1317"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|| 5/5 [00:02<00:00,  1.77it/s]\n"]}],"source":["from langchain_community.document_loaders import DirectoryLoader\n","\n","# Define a function to create a DirectoryLoader for a specific file type\n","def create_directory_loader(file_type, directory_path):\n","    return DirectoryLoader(\n","        path=directory_path,\n","        glob=f\"**/*{file_type}\",\n","        loader_cls=loaders[file_type][0],\n","        loader_kwargs=loaders[file_type][1],\n","        show_progress=True\n","    )\n","\n","# Create DirectoryLoader instances for each file type\n","pdf_loader = create_directory_loader('.pdf', '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data')\n","# docx_loader = create_directory_loader('.docx', './')\n","\n","# Load the files\n","pdf_documents = pdf_loader.load()\n","# docx_documents = docx_loader.load()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1729979705631,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"11PQ6QaPDusr","outputId":"93dc282a-945a-4ebe-d5a6-003c3211ccbc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["95"]},"metadata":{},"execution_count":9}],"source":["len(pdf_documents)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":21,"status":"ok","timestamp":1729979705631,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"mXCJN1SnDuve","outputId":"10a3f03e-f174-4df4-c048-9d3bdff714e0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Document(metadata={'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/mistral_paper.pdf', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/mistral_paper.pdf', 'page': 3, 'total_pages': 6, 'format': 'PDF 1.7', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'PDFium', 'producer': 'PDFium', 'creationDate': 'D:20240719225025', 'modDate': '', 'trapped': ''}, page_content='Figure 4: Performance of Mistral 7B and different Llama models on a wide range of benchmarks. All\\nmodels were re-evaluated on all metrics with our evaluation pipeline for accurate comparison. Mistral 7B\\nsignificantly outperforms Llama 2 7B and Llama 2 13B on all benchmarks. It is also vastly superior to Llama 1\\n34B in mathematics, code generation, and reasoning benchmarks.\\nModel\\nModality MMLU HellaSwag WinoG PIQA\\nArc-e\\nArc-c\\nNQ\\nTriviaQA HumanEval MBPP MATH GSM8K\\nLLaMA 2 7B\\nPretrained 44.4%\\n77.1%\\n69.5% 77.9% 68.7% 43.2% 24.7%\\n63.8%\\n11.6%\\n26.1%\\n3.9%\\n16.0%\\nLLaMA 2 13B\\nPretrained 55.6%\\n80.7%\\n72.9% 80.8% 75.2% 48.8% 29.0%\\n69.6%\\n18.9%\\n35.4%\\n6.0%\\n34.3%\\nCode-Llama 7B Finetuned\\n36.9%\\n62.9%\\n62.3% 72.8% 59.4% 34.5% 11.0%\\n34.9%\\n31.1%\\n52.5%\\n5.2%\\n20.8%\\nMistral 7B\\nPretrained 60.1%\\n81.3%\\n75.3% 83.0% 80.0% 55.5% 28.8%\\n69.9%\\n30.5%\\n47.5% 13.1%\\n52.2%\\nTable 2: Comparison of Mistral 7B with Llama. Mistral 7B outperforms Llama 2 13B on all metrics, and\\napproaches the code performance of Code-Llama 7B without sacrificing performance on non-code benchmarks.\\nSize and Efficiency. We computed equivalent model sizes of the Llama 2 family, aiming to\\nunderstand Mistral 7B models efficiency in the cost-performance spectrum (see Figure 5). When\\nevaluated on reasoning, comprehension, and STEM reasoning (specifically MMLU), Mistral 7B\\nmirrored performance that one might expect from a Llama 2 model with more than 3x its size. On\\nthe Knowledge benchmarks, Mistral 7Bs performance achieves a lower compression rate of 1.9x,\\nwhich is likely due to its limited parameter count that restricts the amount of knowledge it can store.\\nEvaluation Differences. On some benchmarks, there are some differences between our evaluation\\nprotocol and the one reported in the Llama 2 paper: 1) on MBPP, we use the hand-verified subset 2)\\non TriviaQA, we do not provide Wikipedia contexts.\\n4\\nInstruction Finetuning\\nModel\\nChatbot Arena\\nELO Rating\\nMT Bench\\nWizardLM 13B v1.2\\n1047\\n7.2\\nMistral 7B Instruct\\n1031\\n6.84 +/- 0.07\\nLlama 2 13B Chat\\n1012\\n6.65\\nVicuna 13B\\n1041\\n6.57\\nLlama 2 7B Chat\\n985\\n6.27\\nVicuna 7B\\n997\\n6.17\\nAlpaca 13B\\n914\\n4.53\\nTable 3: Comparison of Chat models. Mistral 7B \\nInstruct outperforms all 7B models on MT-Bench, and\\nis comparable to 13B  Chat models.\\nTo evaluate the generalization capabilities of\\nMistral 7B, we fine-tuned it on instruction datasets\\npublicly available on the Hugging Face repository.\\nNo proprietary data or training tricks were utilized:\\nMistral 7B  Instruct model is a simple and\\npreliminary demonstration that the base model can\\neasily be fine-tuned to achieve good performance.\\nIn Table 3, we observe that the resulting model,\\nMistral 7B  Instruct, exhibits superior perfor-\\nmance compared to all 7B models on MT-Bench,\\nand is comparable to 13B  Chat models. An\\nindependent human evaluation was conducted on\\nhttps://llmboxing.com/leaderboard.\\nIn this evaluation, participants were provided with a set of questions along with anonymous responses\\nfrom two models and were asked to select their preferred response, as illustrated in Figure 6. As of\\nOctober 6, 2023, the outputs generated by Mistral 7B were preferred 5020 times, compared to 4143\\ntimes for Llama 2 13B.\\n4\\n')"]},"metadata":{},"execution_count":10}],"source":["pdf_documents[18]"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1729979705631,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"KeBIB57gTwIf","outputId":"5f9b1344-b247-4319-9eba-e65d1aea1a44"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{},"execution_count":11}],"source":["type(pdf_documents)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1729979705631,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"y_cTw-rnY-eI"},"outputs":[],"source":["docs = pdf_documents"]},{"cell_type":"markdown","metadata":{"id":"yPjmN39-Nv1Y"},"source":["**Create LangChain Documents**"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1729979705631,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"E9KThjCwN0Ez"},"outputs":[],"source":["from langchain.docstore.document import Document\n","\n","docs = [Document(page_content=doc.page_content,\n","                 metadata=doc.metadata) for doc in docs]"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":13,"status":"ok","timestamp":1729979705631,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"cFMT5Y0xN_PV","outputId":"b56d2059-17c8-4a8a-dcd0-d56aa25eec48"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(metadata={'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'page': 0, 'total_pages': 15, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240410211143Z', 'modDate': 'D:20240410211143Z', 'trapped': ''}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit\\nGoogle Research\\nusz@google.com\\nLlion Jones\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nukasz Kaiser\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\nEqual contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\nWork performed while at Google Brain.\\nWork performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\narXiv:1706.03762v7  [cs.CL]  2 Aug 2023\\n'),\n"," Document(metadata={'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'page': 1, 'total_pages': 15, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240410211143Z', 'modDate': 'D:20240410211143Z', 'trapped': ''}, page_content='1\\nIntroduction\\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\\nin particular, have been firmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [35, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2\\nBackground\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difficult to learn dependencies between distant positions [12]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3\\nModel Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\\n[10], consuming the previously generated symbols as additional input when generating the next.\\n2\\n'),\n"," Document(metadata={'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'page': 2, 'total_pages': 15, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240410211143Z', 'modDate': 'D:20240410211143Z', 'trapped': ''}, page_content='Figure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1\\nEncoder and Decoder Stacks\\nEncoder:\\nThe encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder:\\nThe decoder is also composed of a stack of N = 6 identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3.2\\nAttention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3\\n')]"]},"metadata":{},"execution_count":14}],"source":["docs[:3]"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1729979705631,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"ccGsE7JYOilo","outputId":"18ebad27-ed12-4250-9f09-1e85abc86c53"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["95"]},"metadata":{},"execution_count":15}],"source":["len(docs)"]},{"cell_type":"markdown","metadata":{"id":"ZaSljqmlOFwm"},"source":["**Split larger documents into smaller chunks**"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1729979705631,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"-f9rqPnROE82"},"outputs":[],"source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=300)\n","chunked_docs = splitter.split_documents(docs)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":200,"status":"ok","timestamp":1729979705826,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"cqqp0RdkOsrg","outputId":"38567c7e-6dae-4774-db98-9833ba7d22b1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(metadata={'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'page': 0, 'total_pages': 15, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240410211143Z', 'modDate': 'D:20240410211143Z', 'trapped': ''}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit\\nGoogle Research\\nusz@google.com\\nLlion Jones\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nukasz Kaiser\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\nEqual contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and'),\n"," Document(metadata={'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'page': 0, 'total_pages': 15, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240410211143Z', 'modDate': 'D:20240410211143Z', 'trapped': ''}, page_content='large and limited training data.\\nEqual contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\nWork performed while at Google Brain.\\nWork performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\narXiv:1706.03762v7  [cs.CL]  2 Aug 2023'),\n"," Document(metadata={'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'page': 1, 'total_pages': 15, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.25', 'creationDate': 'D:20240410211143Z', 'modDate': 'D:20240410211143Z', 'trapped': ''}, page_content='1\\nIntroduction\\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\\nin particular, have been firmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [35, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2\\nBackground')]"]},"metadata":{},"execution_count":17}],"source":["chunked_docs[:3]"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1729979705826,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"q-1rG2xnOqcn","outputId":"6cadd442-b74a-44c5-bde2-5c7e2ae30398"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["204"]},"metadata":{},"execution_count":18}],"source":["len(chunked_docs)"]},{"cell_type":"markdown","metadata":{"id":"1s0vesVjaRU9"},"source":["**Experiment with different embedding models**"]},{"cell_type":"markdown","metadata":{"id":"qMZSsnbYaRU-"},"source":["**openAI embeddings**"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1729979705826,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"Tc6-tyxsaRU-"},"outputs":[],"source":["from langchain_openai import OpenAIEmbeddings\n","\n","# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n","openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":4830,"status":"ok","timestamp":1729979710654,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"C1do4GnTaRU_"},"outputs":[],"source":["# Extract the text content from each document\n","chunked_docs_texts = [chunked_docs.page_content for chunked_docs in chunked_docs]\n","\n","# Pass the extracted text content to the embedding model\n","embeddings = openai_embed_model.embed_documents(chunked_docs_texts)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1729979710654,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"rvO1bTv6aRU_","outputId":"88c42f3d-951c-4723-f1b6-8ea03705deb2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["204"]},"metadata":{},"execution_count":21}],"source":["len(embeddings)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1729979710654,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"IG5TOLIvaRU_","outputId":"873fb338-9dd5-4900-b617-4a3334108340"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1536"]},"metadata":{},"execution_count":22}],"source":["len(embeddings[10])"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1729979710654,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"},"user_tz":240},"id":"_QyweDl6aRU_","outputId":"fdffda2a-52d3-481e-d757-83e70b6ce2f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["[-0.004056982696136587, 0.018843078986182878, 0.06098899990440804, -0.010734951123807507, 0.008615980856290957, 0.020279075950785132, 0.03558469936322005, 0.020722717047147437, -0.03647198155594465, 0.04964112490513732, 0.00701653724550174, -0.029840713367456174, -0.02365308441268485, 0.0017045164713973087, 0.025614446029573534, -0.03890033438878686, 0.04314995184626072, -0.0016125777038133126, 0.009316466748898668, 0.013834603131090976, -0.0349776111550095, -0.030307704583409697, 0.005954132881133275, 0.0047020139173602985, 0.053377050907475215, -0.014149821363669287, -0.01173898205184307, 0.038853637874894716, 0.040534801781979046, -0.03299290314381989, 0.011394576169775732, -0.029280323535782915, -0.05856064707156583, -0.059261135758141265, -0.003697983454986024, 0.014371642843173013, -0.01267880108232535, 0.03623848781061304, -0.060942303390515894, 0.04392048716631952, 0.025450998917725284, -0.020652668551018924, -0.056178994477906065, 0.012655450962734129, 0.01123696658782529, 2.2118218112592224e-05, -0.04964112490513732, 0.05571200326195254, 0.004658233374449334, 0.06355745345479757, -0.055945500732574455, 0.03434717282720772, -0.01500208023965221, 0.01871465705372146, -0.003198886988747789, -0.0024896448012933694, 0.019718687981757025, -0.023746483028404586, 0.013706180267306984, 0.002340791514189634, 0.06715328246487844, -0.03000416047930442, -0.00329228537163688, -0.01601778529616081, 0.025007357821362982, 0.017874073237534146, -0.06425793469079241, 0.003403195645727456, 0.02023237757424784, 0.05575870350113498, -0.0038001376670605356, 0.009112158790410933, -0.011020983569541943, 0.0009193881997089092, 0.013951350935079355, 0.007413479034004176, -0.0012338772649189435, 0.05150908604366112, 0.006532033905516087, 0.004410144407389347, 0.062063079328572114, -0.002005141926969004, 0.022754127160164634, -0.008353298530147742, -0.0056856130250922555, -0.03766280785277454, -0.02596469037286125, -0.0366354286677929, -0.06481832265982052, -0.025474349037316504, 0.006718830205632982, -0.0006213166634675038, -0.00307630212052289, -0.020477548242020215, 0.019508540630726334, 0.013390962034728672, 0.022018617019492665, -0.05295675993070414, -0.015235575847628973, -0.007384292315837725, -0.021107984707176838, -0.012737174518658252, -0.013379286974933062, -0.0401612110443904, -0.017663927749148607, -0.006479497533419702, -0.027785953134847757, -0.018527859822281993, -0.05557190626969551, -0.03250256180827514, 0.02136483043474482, 0.006952325813609744, 0.0400444641717246, -0.006380261853463449, 0.08041581511656509, -0.00443349406131928, -0.05099539831381545, 0.008902012370702816, -0.02323279343591377, 0.009100483730615321, -0.026455029845760848, -0.012655450962734129, 0.018247665837767938, 0.006578733213375955, -0.013192490674816166, -0.027575807646462214, -0.003487837733769839, -0.021843494847848807, -0.032292414457244456, -0.03876023739652983, -0.00811980292217098, -0.008143152110439627, 0.052910059691521696, -0.012760523706926898, -0.01911159977354647, 0.010945097543515624, -0.043733689934880055, 0.021890195087031248, 0.010168724693559018, 0.006718830205632982, -0.008271574974223619, -0.013239189982676034, 0.0019715768285485545, 0.014815283939535316, -0.03266600892012339, 0.09017592668711637, -0.01051896810552416, 0.049501027912880295, -0.011003470979848527, 0.01949686743357587, -0.03558469936322005, -0.054264333100199826, -0.02361806109594317, 0.013320913538600158, -0.037849605084214005, -0.047773160041323225, -0.030611248687514976, 0.037009023130671836, 0.028789984062883318, -0.012141761370243311, 0.06776037067308899, -0.050294909627240016, 0.016671571880908655, -0.0098476689310829, -0.04027795791705621, 0.023629736155738778, -0.022543981671779092, -0.006794716231659301, -0.05136898905140409, -0.048940636218561887, 0.04667573049756793, -0.012970670126635015, -0.026431679726169627, -0.030798044056309294, 0.026198184118192865, 0.01813091896510213, -0.026034738868989764, -0.013017369434494882, -0.04786656051968811, -0.01657817326518892, -0.010402220301535781, -0.0029595543165345088, -0.004681583028379268, 0.02367643453227607, -0.027972750366287227, 0.0037242518738648603, 0.030237656087281184, 0.02652507834188936, 0.03264265880053217, -0.009853506460980706, 0.00424086023130458, 0.029677266255607924, 0.03726586699559467, -0.01189659070247094, -0.03315634653037784, -0.03343654424018219, 0.03149852901759443, -0.017839049920792466, 0.005808198358978442, -0.04364029318180547, 0.023734807968608974, -0.008843638934369914, 0.013180815615020556, -0.025310901925468258, 0.05762666836494908, -0.015434046276218904, -0.037452664227034145, -0.005793604999895216, -0.017255309969527986, 0.005703125149124384, 0.0030179282185286995, -0.06033521518230534, 0.01620458066495513, -0.028089497238953032, -0.000363194820245459, 0.021294781938616305, -0.052583165467825196, -0.011289503425582962, 0.010898398235655755, 0.02309269644365674, -0.011131893843632518, 0.021458227187819406, 0.005364556796954851, 0.014546764083494297, -0.06607919931542407, 0.011044332757810589, -0.017465457320558674, -0.057906862349463135, 0.001637386507387054, -0.01737205870483894, -0.002728977706337293, 0.01059485413155048, 0.015912711620645465, -0.021294781938616305, 0.009812644683018644, -0.015422372147745868, -0.00867435429262386, -0.023758158088200195, -0.00396358454607814, -0.0279960986232333, -0.046488936991418754, 0.024727163836848927, -0.01814259402489774, 0.03763946145847361, 0.006100067403288108, 0.030821394175900515, 0.003225155407626625, 0.023804856464737487, 0.009129670448781773, 0.0060883928091537845, 0.018796380609645585, -0.0043079904281454785, -0.03967086970884566, -0.008382485248314194, -0.031568579376368096, 0.04501791298478452, -0.0160061102363652, 0.017652252689352995, -0.029700616375199145, 0.06299705803518886, -0.007506877184062624, 0.095499619843464, 0.0021072961390435152, -0.011120218783836908, 0.0073025687599136005, -0.03000416047930442, -0.027599157766053435, 0.015165526420177886, -0.023372890428170794, -0.036168437451839376, 0.01123696658782529, -0.0114412754776356, -0.016893392429089805, 0.007985542528489183, -0.03901708126145267, 0.005945377051947854, 0.04097844287834135, 0.00562432082381045, -0.03911048173981755, -0.01601778529616081, 0.010647390969308152, -0.0029974973295476682, 0.03810644894913684, 0.021434878930873334, -0.02059429511468602, -0.003934397827911689, 0.004159137141041743, -0.007197496015720829, -0.022368859500135233, -0.052863359452339255, 0.005040582269529832, -0.05015481263498299, 0.020115628838936885, -0.030587898567923752, 0.003948991186994914, -0.00468450179332817, -0.015550794080207285, -0.050014715642725964, 0.033553291112848, 0.0010813756380444017, 0.0028501034249183844, 0.020629320294072852, -0.016122857109031004, -0.0025480187032875597, -0.0401612110443904, 0.032806105912380416, -0.013180815615020556, 0.05743987113350961, 0.012246834114436082, 0.007652812171878744, -0.017208611592990693, 0.034837514162752464, -0.01564419269592702, 0.03735926374866926, -0.01423154491959341, 0.02463376522112919, 0.02306934632406552, -0.014348292723581792, 0.02303432300732384, -0.04630213975997929, -0.03579484671425073, -0.06808726489678549, 0.007401804439869853, -0.018924802542107003, 0.03187212348047337, 0.013729530386898205, -0.04195912554943084, 0.044901166112118716, 0.0034207077697595845, -0.02039582468609609, -0.0011258856393619484, -0.021411528811282114, 0.0017030570889228574, 0.0012127168011160086, -0.0445509254941213, -0.020652668551018924, -0.0438971370467283, 0.03397358208961908, 0.023734807968608974, 0.05491812154759282, -0.03763946145847361, 0.0007019455661204677, 0.0040686572902709104, 0.029934111983175908, -0.030634596944461048, 0.03392688185043664, 0.00307630212052289, 0.014581788331558555, 0.0658924058092749, 0.007442666217831915, -0.07219678163671202, -0.007646974641980938, -0.014920356683728087, -0.026688525453737608, 0.02325614355550499, 0.02093286253553298, -0.0036337722559246716, -0.048053354025837276, -0.045811798424434544, -0.001968658063599652, -0.0037417639978969885, -0.010641553439410348, 0.04275301098908086, -0.012106737122179054, -0.025147454813620008, 0.0004093466268467635, -0.017652252689352995, 0.01715023815665779, -0.04177232831799137, 0.014418341219710307, 0.010845861397898084, 0.026548428461480582, 0.013367611915137452, 0.011867403984304487, -0.04660568386408456, 0.013916326687015099, -0.026688525453737608, 0.052863359452339255, 0.005577621515950582, -0.0026457947679387173, 0.010320496745611656, 0.0279960986232333, -0.00016600063827682706, -0.009333979338592084, -0.003943153657097109, -0.01116108056179897, -0.023746483028404586, 0.022543981671779092, -0.10722108930561366, -0.003047115169525795, 0.010291310027445204, 0.022567331791370313, -0.0006297079380726161, 0.05608559772483148, 0.00017019626102746799, 0.0015264762332964782, 0.044971216470892375, 0.02234551124318916, 0.025147454813620008, 0.03145183250370229, 0.027108816430508692, -0.002324738772631957, 0.021061286330639545, 0.002739192917997165, 0.02132980525535799, -0.0275057591503337, 0.020465873182224602, 0.019426818937447358, 0.01873800717331268, 0.06080220267296857, 0.07831435650741939, -0.007179983891688701, -0.009771782905056581, -0.03549130261014546, -0.01440666709123727, -0.017430432141171844, -0.02327949181245106, -0.012211809866371826, 0.01411479711560503, 0.06453812867530646, -0.013659480959447115, -0.032759405673197975, -0.08499232679773545, -0.013122442178687653, -0.030261004344227255, 0.02479721233297744, 0.046652384103267004, -0.018959827721493832, -0.023548012599814653, 0.013589432463318602, -0.012573727406810004, 0.07485862821488584, 0.029840713367456174, 0.017944121733662662, -0.001630089827845441, 0.008510908112098186, 0.012538703158745747, 0.02939707227109387, -0.040931746364449205, -0.02498400956441691, 0.04163223132573434, -0.03016760759115267, -0.03946072235781497, -0.022660728544444897, 0.004964696243503513, 0.009415701963193635, -0.046652384103267004, -0.01926337182559911, 0.01755885407363326, 0.02650172822229814, -0.010816674679731632, -0.012060037814319188, -0.006426961161323317, 0.01949686743357587, -0.004900484811611517, -0.020349124446913648, 0.08167669177216864, -0.014803608879739706, 0.04282305762256423, -0.01753550581668719, 0.03224571421806201, -0.028206245974263987, 0.01759387925302009, -0.03350659087366556, -0.039367325604740384, 0.025661146268755975, -0.006432798691221122, -0.038853637874894716, -0.011768168770009522, 0.0062401648612064224, 0.007430991158036305, -0.04095509648404043, 0.004410144407389347, -0.034767467529269104, -0.0035753983539304813, -0.0055980524049316135, 0.026641827077200315, -0.006234327331308617, -0.01078748796156518, -0.01983543485442283, 0.008078941144208918, -0.03644863516164373, -0.0026895753108496824, -0.02359471097635195, 0.016624873504371362, 0.07350435108091742, 0.04011451080520796, -0.017582204193224482, 0.05043500661949704, -0.0458818487832082, -0.01616955734821345, -0.005043501034478735, 0.03859679028468158, -0.010553992353588419, -0.013367611915137452, 0.0007158093503817897, -0.06253007054452564, -0.02594134025327003, 0.005504654254873166, -0.021890195087031248, 0.05608559772483148, 0.0009164694929676674, 0.054264333100199826, 0.004077413585117619, -0.01030882261713862, 0.02325614355550499, 0.00700486218570613, 0.045134663582740625, -0.01712688803706657, 0.021504927427001847, -0.008715216070585922, 0.02291757427201288, 0.0006804201984912591, 0.013729530386898205, -0.017161913216453398, 0.019216671586416666, -0.014640161767891458, 0.008639330044559603, -0.03439387306639016, 0.0177106261256859, -0.03439387306639016, -0.02589464001408759, 0.0027333556209300034, 0.02171507291538739, -0.0031813748647156605, -0.042612910271533536, -0.02100291289430664, -0.10843526572203477, -0.01364780683097408, -0.02075774222653427, 0.023979978636381346, -0.021680049598645706, -0.005081444047491894, 0.028930081055140347, -0.03142848238411107, 0.021411528811282114, -0.0052011101507678905, -0.02350131236063221, -0.011756493710213912, 0.012620426714669872, 0.0012331475736817178, 0.03595829382609898, 0.0205709449950948, 0.023758158088200195, 0.012235159054640472, -0.008347461000249938, 0.02575454302183056, 6.694751209711788e-05, -0.026151485741655572, 0.022649055347294438, -0.035538002849327906, -0.02212369069500801, -0.025030707940954203, 0.0034411386587406153, -0.051742583514283035, 0.03665877878738412, -0.006257676985238551, -0.00867435429262386, 0.0006705695996193564, -0.01565586775572263, 0.008277412504121423, -0.0036016667728093173, -0.01599443517656959, -0.01001695264150638, -0.03469741717049544, 0.03282945603197164, 0.0018037520349382396, -0.02218206413134091, 0.043850436807545856, -0.0205709449950948, -0.061782885344058056, -0.05459122732389632, 0.02076941728632988, -0.03642528504205251, -0.014967055991587954, -0.02385155670391993, -0.015083803795576336, 0.032806105912380416, -0.01008700206895747, -0.024026677012918638, -0.04354689270344058, 0.013939675875283745, -0.01748880557750475, -0.03451061993905597, -0.03416037932105855, 0.004199998453342518, -0.011709794402354043, -0.01587768830390378, -0.023898255080457224, 0.024120075628638375, 0.032922852785046225, -0.02519415505280245, 0.02136483043474482, 0.011342039332018059, -0.03238581493560934, -0.011114381253939102, -0.026618476957609095, -0.010845861397898084, 0.008353298530147742, -0.023723132908813362, -0.006234327331308617, 0.029256975278836844, 0.0008653923869304116, 0.006111742463083718, -0.005040582269529832, 0.02116635814350974, 0.004421819467184957, 0.018726332113517073, 0.028252944350801282, 0.01657817326518892, -0.001205420005159074, 0.006461985409387574, 0.011628071777752495, -0.012445305474348587, -0.010145375505290372, 0.030354402959946993, -0.04597524553628279, -0.030097559095024158, 0.03637858480287007, 0.007133284583828834, 0.026968719438251663, -0.006940651219475421, 0.0290468297904513, 0.031054889783877278, 0.014313268475517536, 0.0037154955790181525, -0.03479081764886032, -0.046979274601673206, 0.004293396603400965, -0.0121300863104477, -0.005481304600943232, -0.010828349739527243, 0.030914792791620252, 0.01890145428516093, -0.008849476464267718, 0.020290751010580744, -0.009217231534603703, 0.008995410986422552, 0.017021816224196372, -0.028112847358544253, -0.03826989606098509, 0.01096844673178427, 0.019683662802370192, -0.03525780513952355, -0.009012922644793392, 0.0013090335997080367, -0.017652252689352995, 0.014056423679272127, -0.0354212522513718, -0.02846308983918682, -0.03147518262329351, -0.037079069764155204, 0.05262986570700764, 0.005014313850650995, 0.02079276554327595, -0.027832653374030198, -0.022076990455825566, -0.019134948030492545, 0.016146207228622228, -0.001685544964890729, -0.03338984400099975, -0.018819730729236806, -0.014733560383611193, -0.02385155670391993, 0.03455732017823841, 0.0042175110430359335, -0.010985959321477686, 0.0031872123946134656, 0.012527029030272712, -0.026851972565585858, -0.025731194764884488, 0.025054058060545423, 0.004039470572104459, 0.049127433450001354, 0.005163167137754731, -0.06323055923110107, -0.005136899184537182, -0.037055719644563986, -0.023688109592071682, 0.003271854482655849, 0.010063651949366247, -0.0015848501352906687, -0.03759276121929117, -0.011622234247854689, -0.03327309712833394, 0.01774565130507273, 0.0014243220212219665, -0.00429923413329877, 0.008236550726159362, -0.028789984062883318, -0.0017804024974236276, -0.028369693086112237, 0.013974700123348003, -0.0043867952191207, 0.018644608557592948, 0.041258640588145705, 0.023186093196731327, 0.034043632448392744, -0.0047049326823092015, -0.03873688727693861, -0.003636691020873574, 0.0008019108208986242, -0.04627878964038806, -0.00028001208557369673, -0.0021788040176464805, -0.01929839514234079, -0.02229881100400672, 0.013145791366956299, 0.015013754368125248, -0.017068514600733664, -0.030938141048566323, 0.017383733764634552, 0.004080332350066522, -0.006753854919358526, -0.026291582733912598, -0.033133000136076916, -0.016893392429089805, 0.016321329400266087, -0.0253576021646507, -0.022240437567673816, -0.020524246618557507, 0.012807223014786767, -0.031031539664286057, -0.022590680048316384, 0.010962609201886464, -0.001701597822863728, -0.03831659630016753, 0.01580763980777527, -0.008843638934369914, 0.023828206584328708, 0.018481161445744698, 0.017839049920792466, 0.01715023815665779, 0.019601939246446067, -0.02703876793438018, -0.003336065681717201, -0.023349540308579574, 0.01604113541575203, -0.0020343286451354552, -0.007991380058386989, 0.012258509174231692, -0.042612910271533536, -0.004372201394376187, 0.021049611270843933, 0.008026404306451245, -0.0009325222927330055, -0.00725586991771502, -0.01241028122628433, -0.004147462081246132, -0.017897423357125367, -0.02022070251445223, 0.006590407807510278, 0.007973868400016147, -0.01058317907175487, 0.0253576021646507, 0.012223484926167436, 0.014243219979389021, -0.013005694374699272, 0.02937372215150265, -0.0039927712642445915, -0.0004170082102146501, 0.012351906858628853, -0.015293949283961876, 0.030261004344227255, 0.005784848705048508, -0.0050347447396320265, 0.009672547690761616, -0.006893951911615554, 0.012013338506459319, 0.03341319412059097, 0.008423347026276257, -0.002041625557507712, 0.0007391588878964015, 0.033810134977770835, 0.03205892071191284, -0.038643490523864024, 0.030214305967689963, -0.021901870146826857, -0.028533138335315338, 0.015060453675985115, -0.02958386763988819, -0.02862653695103507, 0.021971918642955373, -0.006683805957568726, -0.01260875165487426, -0.006532033905516087, -0.0017964553553966266, -0.00572939356800322, 0.026595126838017874, -0.05589880049339201, -0.03261930868094095, -0.01486198231607261, 0.014815283939535316, -0.01736038364504333, -0.0024298115168247276, 0.010769975371871765, -0.02687532082253193, -0.1007766202112098, -0.018609583378206115, 0.020921189338382516, -0.004611534532250754, -0.001738081453402436, -0.0017278660089119207, 0.011155243031901164, -0.017313685268506036, 0.004786655772572038, 0.009333979338592084, 0.013484359719125831, -0.03341319412059097, 0.02692202106171437, -0.0043867952191207, 0.03862014040427281, -0.048053354025837276, 0.015842663124516952, 0.01241028122628433, 0.01911159977354647, -0.03056454844833253, -0.009018760174691198, 0.0038526742719875644, 0.041048493237115014, 0.036004990339991126, -0.024587066844591898, -0.005116468295556151, -0.0003611881984469189, -0.06005501747250099, 0.019975531846679856, -0.004526892211377727, -0.01985878497401405, 0.01699846610460515, -0.001312682055894165, 0.029490470886813606, 0.005093118641626217, 0.0003239748766709851, 0.007250032387817215, 0.020115628838936885, 0.0067246677355307875, 0.012445305474348587, 0.014535089023698686, -0.021668374538850097, 0.011604721658161274, -0.050061415881908405, 0.026571776718426653, 0.0035141059198180316, 0.014803608879739706, 0.004456843715249213, 0.020851140842254003, 0.0023232793901575054, 0.015515769832143029, -0.005679775960855738, -0.018574560061464435, 0.007372617721703402, -0.016181232408009057, 0.019566915929704387, -0.012515353970477101, 0.012433630414552976, 0.013963025063552393, -0.004853785969412937, 0.01717358641360386, 0.03345989063448312, 0.013309238478804547, 0.029443770647631165, -0.025264203548930966, -0.040091160685616745, 0.022217087448082595, 0.037686157972365755, 0.00264433561829491, -0.03810644894913684, 0.003619178896841446, -0.00767616136014739, 0.005212785210563501, -0.014710211195342547, -0.017722301185481508, -0.008756077848547985, 0.007179983891688701, 0.06388434022791346, -0.007909657433785439, -0.008580956608226699, 0.06327725947028351, -0.008113965392273175, -0.041492134333477315, 0.027132166550099913, 0.02136483043474482, 0.010962609201886464, -0.00767616136014739, -0.023933280259844054, -0.04226266965353612, 0.0339969322092103, 0.05636579170934553, 0.0006318969535766322, -0.04779651016091445, 0.0066371071153701455, -0.028112847358544253, -0.0033623338677653937, 0.04343014583077478, -0.010834187269425049, 0.07873465120948077, -0.003423626534708487, 0.05949462950347288, 0.034440573305572604, -0.03822319954709294, 0.0004783007607424215, -0.015574144199798506, 0.021306455135766768, 0.005951214116184372, -0.01440666709123727, 0.024446969852334872, -0.02540430054118799, -0.0026268232614321376, 0.0030033346266148298, 0.0014593462692862233, -0.012013338506459319, -0.030401101336484285, -0.0059220273980179206, 0.020559269935299187, 0.02041917294304216, 0.061502691359544004, 0.007448503747729721, 0.002820916473921289, 0.0039081294090328525, -0.0031697002705813374, 0.04982791841128649, -0.032922852785046225, -0.007413479034004176, -0.002568449592268591, 0.04044140502890446, -0.027575807646462214, -0.021785121411515902, -0.0016665734583841492, 0.031732026488216346, 0.017091864720324885, 0.00934565346706512, -0.02271910384342295, 0.042682960630307194, 0.029256975278836844, 0.012643776834261093, -0.048100054265019725, 0.009579149075041883, -0.004418900702236054, -0.025731194764884488, 0.033716738224696244, -0.005618483293912645, 0.009789294563427423, 0.031685326249033904, -0.019204996526621058, 0.016870044172143734, 0.013029043562967918, -0.007681998890045195, 0.0026749817189358127, -0.009129670448781773, -0.0044685183093835365, 0.03289950266545501, -0.007343430537875662, -0.017582204193224482, -0.01697511598501393, -0.019193323329470595, 0.03402028232880152, 0.05669268593304203, -0.007553576491922491, 0.013916326687015099, 0.015725916251851144, 0.014535089023698686, 0.047446265817626725, -0.020524246618557507, -0.040207907558282546, 0.008960386738358295, 0.016356352717007767, -0.01011618878712392, -0.0021306455601428054, -0.02440026961315243, 0.011388738639877927, 0.04214592278087031, 0.04438747838227305, 0.0012740093516437798, 0.0012820357224226184, 0.016508124769060405, 0.00433717714631193, 0.007191658485823024, 0.0045589976944930815, 0.0034382198937917127, -0.025871291757141517, 0.002620985964364976, 0.028789984062883318, 0.030214305967689963, 0.012141761370243311, 0.01869130693413024, 0.02079276554327595, -0.016297979280674866, 0.011628071777752495, -0.009882693179147159, 0.00229409243916041, 0.022754127160164634, 0.01873800717331268, -0.011954965070126417, 0.012270183302704728, -0.001717650564421405, -0.014838633127803962, -0.001000381889772825, 0.018656283617388556, 0.010174562223456824, 0.0077637224459693194, -0.007501040119826105, -0.04408393427816777, 0.01351938396719009, 0.026618476957609095, -0.010892560705757951, -0.007010699715603935, 0.0034820002038720337, 0.02822959423121006, 0.017080189660529276, -0.01751215569709597, 0.02213536389215847, -0.033810134977770835, -0.000489610712984945, -0.005568865686765162, 0.007039886433770386, -0.02059429511468602, 0.0007085126126325159, -0.01238693110669311, -0.010203748941623274, -0.003417789004810682, -0.0080030551181826, 0.017792349681610024, 0.02329116687224667, 0.001138290157564141, 0.01058317907175487, 0.0019161216915032668, 0.005560109391918454, -0.001230228925148137, -0.007664486766013067, 0.0007814799319175932, 0.006666293833536597, -0.013986375183143614, -0.008084778674106724, -0.005580540280899485, -0.032806105912380416, 0.025637796149164754, 0.007868795655823378, 0.008756077848547985, 0.016297979280674866, -0.004990964196721062, -0.01079916302136079, 0.003108407603638244, -0.008639330044559603, -0.023244468495709377, 0.03871353715734739, 0.02958386763988819, -0.026034738868989764, -0.017815699801201245, 0.0016928417608476638, 0.02213536389215847, -0.001303925877462779, -0.003928560298013884, 0.003592910710793253, 0.011190267279965421, 0.017138563096862177, 0.03352994099325678, 0.017628902569761774, 0.0040628202260343926, 0.04359359294262302, 0.02323279343591377, -0.04209922254168787, 0.01351938396719009, -0.005913271103171212, -0.008470046334136123, -0.033039599657712033, -0.006397773977495578, 0.05043500661949704, -0.026968719438251663, 0.014126472175400641, 0.0014469418674993527, -0.01906489953436403, 0.027809303254438977, 0.020477548242020215, 0.031054889783877278, -0.008423347026276257, 0.0200806055221952, -0.05645918846242012, -0.016286304220879254, -0.03182542324129093, 0.015609168447862764, -0.03357664123243922, 0.008680191822521666, -0.016799993813370072, -0.011342039332018059, 0.007144959643624445, 0.05108879506689004, -0.022847525775884368, -0.02421347424435811, 0.015282274224166266, 0.0061642788351801035, 0.00021197005117265557, 0.0098476689310829, -0.0017205693293703076, 0.03149852901759443, 0.03128838539185404, 0.013682831079038338, -0.01967198774257458, 0.012958995066839405, -0.015936061740236686, 0.025124106556673936, 6.256947381312817e-05, 0.06098899990440804, 0.03430047631331558, -0.0032806105446719133, -0.05206947773797953, -0.028930081055140347, -0.01927504688539472, -0.03112493828000579, -0.0032981226687040415, 0.015013754368125248, 0.009964416735071282, 0.00278735137550084, 0.004661152139398237, 0.00229409243916041, -0.055058218539849844, 0.0025100756902744, -0.0129006216305065, 0.011166918091696775, 0.0036250161939086075, 0.010051976889570637, 0.013239189982676034, -0.002803404349889161, -0.05300345644459628, 0.004456843715249213, -0.019321745261932012, -0.0020474628545748734, -0.004226266872221354, 0.022415559739317675, -0.013099092059096432, -0.010005278513033344, 0.011091032065670456, -0.06916134059565926, 0.004582347348423015, -0.002340791514189634, 0.004270047415132319, -0.024143425748229596, 0.007191658485823024, -0.005735231097901025, 0.004845029674566229, -0.017045164481142443, 0.0007807502988880285, -0.01906489953436403, 0.00841750949637845, -0.022999297827937006, 0.02310437150345235, 0.030331052840355772, 0.004007365088989105, 0.028509790078369263, -0.014897007495459441, -0.02671187557332883, -0.000447289639859923, 0.006368587259329126, 0.03911048173981755, 0.01946184225418904, 0.006993187591571807, -0.03777955845073064, -0.023512987420427824, 0.012351906858628853, 0.03932062536555794, -0.013297563419008937, 0.009012922644793392, 0.023337865248783965, 0.009859343990878513, -0.03128838539185404, 0.022252112627469428, 0.0002561152796311656, 0.0389470346279693, 0.02650172822229814, -0.014383316971646048, -0.03609839081835601, -0.0018168861279623358, -0.021294781938616305, 0.023583035916556336, -0.048707142473230276, 0.013764554634962461, 0.0011397494236232704, 0.018481161445744698, -0.02519415505280245, -0.047773160041323225, -0.003671715268937831, 0.020337449387118036, -0.0135310590269857, 0.04880053922630486, -0.02024405263404345, 0.01620458066495513, -0.025240853429339745, 0.016554825008242846, -0.001673870254341084, -0.00480708666155307, 0.002167129190681514, -0.001331653445985423, -0.0361917875714306, -0.0034644880798399055, 0.009094646200717517, 0.0175471808764828, 0.017605554312815703, 0.008294924162492265, 0.0013754338724810658, -0.002469213912312338, 0.013145791366956299, -0.007028211839636063, 0.0015016673133074149, -0.01423154491959341, 0.002912855241505285, 0.003718414343967055, -0.0009274145704877476, -0.0012827654136598442, -0.028649887070626292, 0.01678832061621961, -0.017302010208710427, 0.011067681946079235, 0.011487973854172892, -0.024446969852334872, -0.041725628078808925, 0.006380261853463449, 0.015153852291704848, 0.035771496594659516, -0.026221534237784085, 0.001409728545723419, -0.015737591311646756, -0.0023991654161838244, 0.011371226050184511, 0.01564419269592702, 0.0017147319158878243, 0.0010456215823275974, -0.013390962034728672, 0.03822319954709294, -0.010302985087240816, 0.013110767118892043, -0.037499364466216586, -0.02171507291538739, 0.026268232614321377, -0.008802777156407851, 0.035327855498297214, -0.013496034778921442, -0.0017555935774345645, 0.027365662158076676, -0.016099508852084932, 0.02234551124318916, 0.012643776834261093, -0.02554439753344502, 0.01959026418665046, 0.0025874210987751707, 0.03299290314381989, -0.018049195409178004, -0.04336009919729141, -0.0036162601318925434, 0.007325918413843534, -0.02517080493321123, 0.007489365060030495, -0.022637380287498825, -0.04583514854402576, -0.009223069064501509, -0.049687821419029464, -0.004783737007623136, 0.02379318140494188, 0.009333979338592084, 0.020290751010580744, -0.00021032828954464352, 0.024003328755972567, 0.0042291856371702565, -0.021224733442487792, 0.010840024799322853, 0.0025027790107327876, 0.02671187557332883, 0.03486086428234369, -0.022076990455825566, 0.018235990777972326, -0.03563139960240249, 0.026244884357375306, -0.009275604970936607, 0.0051106307656583454, -0.004836273845380808, -0.000804829469432205, 0.010997633449950722, -0.02308102138386113, 0.006783041637524978, 0.01448838971583882, 0.016718272120091096, -0.004249616526151288, -0.007395966909972048, 0.03273605555360676, 0.037849605084214005, -0.00821320060656814, -0.009158857166948225, -0.012200134806576215, -0.01602946035595642, 0.02862653695103507, -0.002340791514189634, -0.023349540308579574, 0.011423762887942184, 0.0324558615690927, 0.028206245974263987, 0.005285752471640917, -0.008703541010790312, -0.017442107200967453, -0.003639609785822477, 0.007670324295910872, -0.02212369069500801, -0.0400444641717246, 0.004815842956399778, 0.003552048932831191, -0.016671571880908655, -0.0025917990133678807, -0.025427650660779212, 0.007862958125925572, -0.0160061102363652, 0.014628487639418422, -0.004267128650183416, -0.014371642843173013, 0.012013338506459319, 0.04702597484085565, 0.015585818328271541, -0.0015060453443154472, -0.048146754504202166, -0.009409865364618403, -0.005227378569646727, 0.003986934200008074, -0.008522582240571222, -0.010553992353588419, 0.00700486218570613, -0.0009573311545144077, -0.009812644683018644, 0.012060037814319188, 0.02212369069500801, -0.012842247262851023, 0.012912295758979536, -0.009584986604939687, 0.008283250034019229, -0.014465040527570174, -0.001000381889772825, 0.004421819467184957, 0.037405963987851704, -0.019146623090288153, 0.0149904051798566, 0.014605137519827201, 0.013029043562967918, -0.005530922673752003, -0.01959026418665046, -0.02575454302183056, -0.01325086411114907, -0.0011871781898897197, 0.013344262726868804, 0.008744402788752374, 0.009865180589453742, 0.02692202106171437, 0.017278660089119206, -0.005405418574916913, -0.007594438269884553, -0.026992069557842883, 0.003341902978784363, 0.01147046219580205, 0.0017876991769652407, 0.00010479930642966655, -0.006952325813609744, 0.024190124124766888, -0.00767616136014739, -0.0039927712642445915, -0.0014710210962511903, 0.014698536135546935, -0.015924386680441074, 0.027202215046228426, 0.008242388256057167, 0.03911048173981755, 0.007565251086056814, -0.03579484671425073, -0.012293533422295949, -0.013671156019242727, 0.0016870043473651802, 0.03943737596351405, -0.012597077526401225, 0.01375287957516685, 0.014815283939535316, -0.009001247584997782, 0.005291589535877435, -0.015679216012668702, -0.005314939189807369, -0.017815699801201245, -0.028743285686346026, 0.031358432025337404, 0.006607919931542407, 0.021306455135766768, -0.015690891072464314, -0.014394992031441659, 0.012480329722412845, -0.0017191099468958563, 0.022415559739317675, 0.006000832188993142, 0.037125770003337645, 0.019333420321727624, 0.004810005426501972, 0.0025553153828291727, 0.006829740479723558, -0.009304791689103057, 0.027832653374030198, -0.044971216470892375, 0.03189547360006459, -0.022765802219960243, 0.0200222320858623, -0.007144959643624445, -0.05127559229832951, -0.015784289688184048, 0.0040715760552198135, -0.0006950136739898067, -0.00085298792693588, 0.01114940550200336, 0.028509790078369263, -0.010133700445494762, 0.030214305967689963, 0.03642528504205251, 0.001873800647482075, -0.005682694725804641, -0.013029043562967918, -0.00343530112884281, 0.013857952319359622, -0.036962322891489395, -0.023197768256526936, -0.0007763722096723354, -0.0175471808764828, -0.015585818328271541, -0.004786655772572038, 0.01849283650554031, -0.0011572616640707206, -0.007419316563901981, 0.021668374538850097, -0.0004078873025799731, -0.03175537660780756, 0.00045641054749460003, 0.0037505200599130526, 0.007903819903887634, -0.04819345101809431, 0.03224571421806201, 0.02037247456650487, 0.002695412607916844, 0.028766633943292097, 0.004500623792498891, -0.015142177231909238, -0.014826958068008352, 0.0020357880276099067, -0.01364780683097408, -0.03766280785277454, -0.008347461000249938, -0.017138563096862177, 0.0049442653545224815, -0.00178478052843166, 0.03259595856134973, 0.03250256180827514, -0.007787072099899253, 0.02113133482676806, -0.024563716725000677, 0.012153436430038921, 8.856407657906449e-05, 0.053657244891989274, 0.001869422616474043, 0.04382708668795464, 0.023933280259844054, 0.006818065885589235, -0.024096725509047155, 0.006030018907159594, -0.02093286253553298, -0.005037663504580929, 0.002361222403170665, 0.0059833200649610134, -1.4821486047660292e-06, -0.0006815147353470976, -0.01636802777680338, 0.08587960899046006, -0.038690190763046466, -0.016543149948447237, -0.0012980885803956174, -0.008435022086071867, 0.03161527961555054, -0.04627878964038806, 0.009182207286539446, 0.0209562126551242, 0.013916326687015099, -0.0050347447396320265, 0.03873688727693861, 0.022252112627469428, 0.03418372944064977, 0.0016826263163571482, 0.007285056635881472, 0.00319596845662953, 0.05631909147016309, 0.02731896191889423, 0.04616204276772226, -0.024166774005175667, -0.048707142473230276, -0.0005757121252941186, -0.008370810188518584, -0.005495897960026458, 0.013916326687015099, -0.0029157740064541878, -0.03738261386826048, -0.03892368450837808, 0.01601778529616081, 0.016648221761317434, -0.0028107010294307734, 0.024050027132509862, -0.0060708806851216554, -0.007203333545618635, 0.011569697410097016, 0.0366354286677929, -0.009386515245027182, -0.004500623792498891, -0.01830603927410084, -0.011207779869658837, -0.004973452072688934, -0.009363166056758536, 0.04095509648404043, -0.026968719438251663, -0.02671187557332883, -0.022602355108111996, -0.012083387002587834, -0.04065155237993515, -0.017021816224196372, -0.027832653374030198, 0.005711881443971092, 0.05762666836494908, 0.04336009919729141, 0.030938141048566323, 0.003029603045493666, -0.0008894715574745882, -0.035608049482811266, -0.006794716231659301, 0.030377753079538213, 0.021388178691690893, 0.003969422075975945, -0.052022777498797086, -0.030237656087281184, -0.0056126457640148395, 0.021668374538850097, -0.0068122283556914295, -0.022427234799113287, 0.026595126838017874, 0.017815699801201245]\n"]}],"source":["print(embeddings[10])"]},{"cell_type":"markdown","metadata":{"id":"DYZco5zjaRU_"},"source":["**Open Source Embedding Models on HuggingFace**\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"mDlEH_J3aRVA","colab":{"base_uri":"https://localhost:8080/","height":473,"referenced_widgets":["be16f7f8652248b3ade29e9384d75d46","da2a358c855b49b28b8ecc506bb8bbdd","d31c267d5b6c44b4973d0656f29afb02","fe69d80aca0b4e488d15f1efcacfd81b","160ac6ee86384dbcbde79031aba8b4f1","963824d5b57e4ca9a638750da159a036","91957b0253524e0bbf97d5003b43fec6","988971546ac341d4a1783a3d195b7d7e","6e1d7a6a81574fdb9e95a2cf07514c31","ea69c2ce10a24ba4aa1e99cf6c2930a2","fdcab46f1e504316a56b12b54808b63a","8acf8fd5ec5d4126b01fec6626a77cde","ed132ee12f654da0ad845b4714e6fd47","63c485b2dd8e4090a51484e1484248a9","8fe64bdec5f14f41a4b3f5b3584c1967","ef86f32e69e34221931e87225e64ba42","40d1e21bb14742af91ea1eecae02ee52","64a3607f83ef448da3ccf81c84b8ebe6","382c1463ece24c39876070b2f7b3df80","6e9c824d83e14326b940f6131452e29e","9b9f74212a604e659ee6d5dadaebd38f","5d838d84c621405ca075eea86e1ddf25","bcc8b5a83d1347ae990641329bd34291","82de1f0380574863a01f0e2c78d4f92a","cafca01490d541c1affbfba39d6384aa","9ed067e11cc94a52b48112b16ba0138b","d2d7c1e7d37c43e4aaed7e0e449480b0","28a72d2fcb7c48e8b6e53521169e917c","40bc7da138f84f6486bdb2ddfcccceb5","0c206ddb1a3d4cdcb603d7e93b0b28a7","5086f3332cea4eeb8022e0a23a88da17","522c4d012299407c95679ae3d1f417a4","2cef87aecab845fc9d20ac292ff95d7e","6f4f5b9da1ae4982a742b047232d6402","3b3028b251ad48c9aabf3e5959c31019","d2a63cc3344a4b48b7f9ac4f9928542e","0779c22b040748ad9baab6bd95aec9ec","b447ccd169374d6d9ae6f47f77300088","adac9dd759524b2594e8ea65587352c4","8691bc7c6a464e7aba44d4eea116aedf","8283a25fe37247339c884fb2088e956d","45298a9b93ea47c58b1ff0e8a097b4e7","cdfc7a173a4041e08b6e88187955cbd8","ae4500dadf4444cea7ad1b4c554c8ea2","00cddbb810564830b147ce4bf0c85d58","b49eeecebdc74cf2b8d4e890a7bb15f3","52ba8515ba204aec93bf5276e21cb87d","47039b89a8034b09a03cbb5ae228e135","c8387d65ad074567a740c6caac9f3b52","9cab96160e70481a8464d01d2a1c5fa1","5c1b9cc1d354480998e01795e8b76b31","c4ea8f0d7c42467d9d67e26cc0750d1a","74c20b420ac240398778318fbe502097","d877b0e648144e6f9d3857fbc4642ed4","423a19fbbdc4465b9fe2ac8fe11d7cf9","75684d39258d4abc88c57f6649e05899","fb045f639b4e4618bc10a94ee1b9bd73","e8cbb8360eb14ab59e1e8d4fcb175e51","ca289490c3e14739907d87a3bd55bdb2","c0a28e01e0154f149470804990737e68","704fff10e741467187e2ae6cb18af0a9","5de58da74e994c8f9ce46aa1cf1d9009","ca6757b720134a6c867f3abceb18ebee","f7ea5c3811364a71a4ce9274b9ff7020","488f061fcdd54cb3917a94a48b0a1bce","57c9c46ee7594340b55a1e13c12e9db4","005b2b2b884f43ca8634d3049ed63916","0364b012d38643a6b0378065b9a440ca","cf3f2c39b0904c6f85585136ffd63b54","b01725590be74304907020cc9f3637f7","30b312e89df24a2cb0d226935d4f3bff","6b953f8e33e94748ab33fdd24beda50e","fcb1aa09d6a24c43934e9e8c2f2c433e","a16d2e96e34844ccbb927c0cebf1d975","996e309bb72447589d93b551b544fc42","a745ebcc29274242a7dafe2e6402d6d7","9807ed2e705a4ad299643b60f816a6f0","c1330c8cd9a94e3f9c3e1c0b011d9f25","2604dae17c584bf6a58ffeda053d11f7","effe2a9aa6204fa1bc4d5b2cea521dd8","ea6778343afd414780f7e93dbf6d5f0b","88bb23e459704147b655aa39304dda06","ec113fe92bb54f41958f284d190e07b4","a99a1037ea4b4640aedc7807922cacd5","cb4f271081f14b5a97417414dd2486ed","3b782a39c6624351a92b5197145374ed","54e8ecc154a44b378b4c5cc5e66dd9e8","e8a7246f0c3a4f64b8b5eb995a155b92","37eb087c67f84d91b83673e8264d38fc","8ba7a0f4f8294564ae672bdc7f90e1a7","402d48cbdc744c7b9dd99e4cbb81b75b","8dcb24dffdce4a8096a3bd6a477804d6","c61d14b7cdf64632b009b079a569e9b2","9527ae784e64439c9bb0b18babb54357","017663ef0da14ae3861eb693c9476e39","0860456d367f4480a42b932ab91500cc","27175400ced0452eb0d2df5cdf1dbaab","9148dd80b6cf4e8b96a640c69a4eb032","34961aea41a04284a16cd848c74d38d5","1efe091191d04d0cbda363366ed51045","0158ce533cd34bbcbc18874db8100db9","d337922792c042b0ad31c5534167a6b3","355eb604c996435cab9524bea9c36bbb","33cc81b74ec14c44ad81e1b4372fc589","11ed69d1777049d5b6427bbe33484e42","348c4d3b2ce04ed6ba1b62bbd49b54c6","5366dceb652443b58795167452f649c0","4b9490aca59842359a984f5920e709b7","a441256a8e4b459b86792b2779e6b200","42cffad6bdab4f2ea9840068ee31c32e","ce1bf2dff62940d2adb3c5548f55e066","822ecdaba0a34e918f6243302b8d70f8","96a3c38e37ec4ad7ad297774e49fc8a4","96ed114f5584405ca3e1cb88f813a6b9","a63bccc5fb5942878b518816b982d419","4e1889ad6da14950a07b7af0a9ae52bf","5c6ec71fc0134fdca945ce7d966c01f1","df78299c13124789aa6e86fcbbdfe724","4cbd9563feba4fed8d51ac8386cce50d","e5ae94e17843444bba1326d21835c878","1cb8265c943a4c9b822893f78a74962a"]},"executionInfo":{"status":"ok","timestamp":1729979790873,"user_tz":240,"elapsed":80224,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"0ee20bbb-f89b-49b4-d758-4d1d9dd4ec6e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be16f7f8652248b3ade29e9384d75d46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/171 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8acf8fd5ec5d4126b01fec6626a77cde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/114k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcc8b5a83d1347ae990641329bd34291"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f4f5b9da1ae4982a742b047232d6402"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00cddbb810564830b147ce4bf0c85d58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75684d39258d4abc88c57f6649e05899"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"005b2b2b884f43ca8634d3049ed63916"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1330c8cd9a94e3f9c3e1c0b011d9f25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37eb087c67f84d91b83673e8264d38fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1efe091191d04d0cbda363366ed51045"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["1_Pooling/config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce1bf2dff62940d2adb3c5548f55e066"}},"metadata":{}}],"source":["from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n","\n","# check out model details here: https://huggingface.co/mixedbread-ai/mxbai-embed-large-v1\n","model_name = \"mixedbread-ai/mxbai-embed-large-v1\"\n","\n","hf_embeddings = HuggingFaceEmbeddings(\n","    model_name=model_name,\n",")"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"4WDgFaUUaRVA","executionInfo":{"status":"ok","timestamp":1729979808210,"user_tz":240,"elapsed":17339,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["embeddings = hf_embeddings.embed_documents(chunked_docs_texts)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cxbbyq4BaRVA","executionInfo":{"status":"ok","timestamp":1729979808211,"user_tz":240,"elapsed":9,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"e1524c13-689f-42a9-e708-5368fe273421"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["204"]},"metadata":{},"execution_count":26}],"source":["len(embeddings)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SBFRIRZ4aRVA","executionInfo":{"status":"ok","timestamp":1729979808211,"user_tz":240,"elapsed":8,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"c24748b6-1147-4810-f816-9f98b368758c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1024"]},"metadata":{},"execution_count":27}],"source":["len(embeddings[0])"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"tuxz5jiFaRVA","executionInfo":{"status":"ok","timestamp":1729979808211,"user_tz":240,"elapsed":6,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"03dd0e40-8054-4714-97ed-0af8aa6c4c11"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0.2757548987865448, 0.3845578134059906, -0.4568205773830414, -0.2763338088989258, 0.029887191951274872, -0.02544581890106201, -0.03740381821990013, -0.37605324387550354, -0.4465924799442291, 0.5872412323951721, 0.7079259157180786, 0.10372361540794373, -0.04959478974342346, -1.0523818731307983, -0.377909779548645, -0.5055117607116699, -0.0463903471827507, -0.5088703036308289, -0.7846989035606384, -0.46400272846221924, 0.19471679627895355, -0.23496495187282562, -0.9955841898918152, 0.05174575373530388, -0.25899073481559753, 0.24758705496788025, 0.6653371453285217, 0.17045192420482635, 1.615617036819458, 0.6573950052261353, 0.6480590105056763, -0.37707313895225525, 0.6688839197158813, -0.28713661432266235, -0.0995987206697464, -0.6994351148605347, 0.4054013192653656, -0.04849502444267273, -0.4991722106933594, -0.22345030307769775, -0.07443972676992416, -0.411498099565506, 0.4122215211391449, -0.6318870186805725, -1.4490340948104858, 0.07992646843194962, 0.5553582906723022, -0.702592670917511, -0.19724348187446594, -0.2874123156070709, -0.4993443191051483, 0.2459392100572586, -0.027497461065649986, 0.5644997358322144, 0.44595101475715637, -0.4399469196796417, 0.10565024614334106, 0.04172416031360626, -0.8818047642707825, 0.06953125447034836, 0.9741860032081604, 0.274372935295105, 0.30759891867637634, -1.433330774307251, -0.8619729280471802, 0.07496341317892075, 0.4424203336238861, 0.2780299782752991, -0.08953312039375305, -0.5894126892089844, -1.3255237340927124, 0.07441210001707077, -0.14254790544509888, -0.2429344654083252, 0.1829560548067093, 0.13602647185325623, -0.16958215832710266, 0.42613786458969116, -0.40844157338142395, 0.7989189028739929, 0.4833686947822571, 0.45863115787506104, -0.2897889316082001, -0.09251915663480759, -0.6170216798782349, -1.1096745729446411, 1.2145122289657593, -0.2670519948005676, -0.5648400187492371, -0.4915545582771301, -0.6199849843978882, 0.2671256959438324, -0.34752213954925537, 0.30708715319633484, 0.16743358969688416, 0.631736695766449, 0.18267212808132172, 0.16289418935775757, 0.22523942589759827, 0.1234259307384491, 0.32822299003601074, 1.3166959285736084, -0.7129560708999634, 0.8459221124649048, -0.8533018231391907, -0.7572494149208069, 0.5076978206634521, -0.3338337540626526, -0.3739175796508789, -0.42911526560783386, -0.18089382350444794, -0.015593083575367928, 0.7995215654373169, -0.2878742218017578, -0.571972668170929, 0.7563130855560303, -0.3519860506057739, 0.17278924584388733, -0.5834373235702515, -0.06865566223859787, -0.6159359216690063, -0.4536534249782562, 0.2651503384113312, 0.32374799251556396, 0.6712855696678162, -0.5746564269065857, -0.02207644097507, 0.4332115352153778, -0.5702304244041443, 0.3722165524959564, 0.7525814175605774, 0.2512584626674652, 0.24106064438819885, 0.8881268501281738, -0.7497749328613281, -0.2750922441482544, -0.4279954433441162, 0.1687885820865631, 0.17235752940177917, 0.1138751208782196, -0.21509765088558197, -0.5300407409667969, -0.10976916551589966, 1.6372771263122559, -0.06999410688877106, 0.40139418840408325, -0.289713978767395, -0.3926331698894501, -0.7750592231750488, 0.41785186529159546, 0.22289757430553436, 0.19171413779258728, -0.25181204080581665, -0.07785642147064209, -1.132452130317688, -0.15010100603103638, -0.04196945205330849, -0.2146897166967392, -0.16237342357635498, 0.07105042785406113, 0.2771497964859009, 0.1593788117170334, -1.1235333681106567, 0.6434678435325623, -0.3625733554363251, 1.146544337272644, -0.1880720853805542, -0.4410841763019562, -0.38164961338043213, -0.3012460470199585, -0.23314149677753448, 0.42006251215934753, 0.05591624975204468, 0.44829171895980835, 0.36952415108680725, 0.9000450968742371, 0.6055970191955566, -0.3328891396522522, 0.2513367533683777, -0.27338898181915283, -0.08756627142429352, -0.5036175847053528, 0.0504494346678257, 0.11415865272283554, -0.13292869925498962, 0.09168510884046555, -0.011279392056167126, 0.3486717641353607, 0.10066766291856766, 0.2864566445350647, 0.10424560308456421, 1.0946660041809082, -0.5324749946594238, 0.05350904166698456, -0.6189659237861633, 0.5751987099647522, -0.25972050428390503, 0.020258253440260887, 0.6755527257919312, -0.5404635667800903, -0.2437707483768463, 1.087813138961792, -0.006830207072198391, 0.08018587529659271, -0.9144758582115173, 0.2765030562877655, 0.588394045829773, 0.848724365234375, -0.6124672293663025, 0.6444516777992249, -0.10769617557525635, 0.132035031914711, -0.23567897081375122, 0.376395046710968, 0.7990867495536804, -0.39207586646080017, -0.8225464224815369, 0.32775798439979553, 0.3666929602622986, -0.023689087480306625, 0.11454200744628906, 0.031115131452679634, 0.00468392763286829, -0.4719295799732208, 0.27646583318710327, -0.07404433935880661, 0.9301369190216064, 0.8037251234054565, -0.039309702813625336, 0.5184444785118103, 0.6471422910690308, 0.10607802867889404, -0.36497586965560913, 0.9003152251243591, 0.511387050151825, 0.6563868522644043, 1.1786894798278809, 0.813177227973938, 0.8554277420043945, -0.09204410016536713, -0.3620337247848511, 0.06408914923667908, 0.7031018733978271, 0.7369188070297241, 0.17086854577064514, 0.7367422580718994, 0.01535127591341734, -0.16311778128147125, -0.6089187264442444, -0.4930904507637024, -0.5729561448097229, 0.5221956968307495, 0.25744375586509705, 0.22617416083812714, -1.0758967399597168, -0.18450923264026642, 0.3585227429866791, 1.0449492931365967, -0.14434564113616943, -1.5100154876708984, -0.5495491027832031, 0.6369714736938477, 0.22566908597946167, -0.3245920240879059, 0.41363683342933655, 0.45237207412719727, -0.1796899139881134, 0.6060535907745361, 0.4142098128795624, -0.2300969362258911, -0.773664116859436, -1.5508137941360474, -1.6653517484664917, -0.2646346688270569, -0.8209479451179504, -1.2210087776184082, 0.03494727611541748, -0.5796239376068115, 0.2898162305355072, 0.06785423308610916, -0.3516333997249603, 0.415583997964859, -0.525449812412262, 0.7248330116271973, 0.38830915093421936, 0.29213982820510864, -0.7563559412956238, 0.8296968340873718, -0.08492245525121689, 0.7892079949378967, 0.46312734484672546, -0.38613447546958923, -0.35812756419181824, -0.020395392552018166, 0.20648597180843353, 0.5226956605911255, -0.28846338391304016, 0.13771604001522064, -0.4520004987716675, 0.34797582030296326, 0.16799768805503845, -0.5544887185096741, 0.4544088542461395, 0.1857127845287323, -0.41566604375839233, 0.4412311911582947, 0.02470736764371395, -0.35840630531311035, 0.5379482507705688, 0.7096467018127441, -0.7652722001075745, 0.7394999861717224, -0.07272946089506149, 1.4494422674179077, -0.28111472725868225, 1.2470380067825317, 0.5571412444114685, 0.14133110642433167, -0.16009418666362762, -0.3786240816116333, -0.7796490788459778, -0.0009056280832737684, -0.4138464331626892, -0.730368971824646, 0.5549723505973816, 0.4802258312702179, -0.6080356240272522, -0.9135671257972717, -0.25076037645339966, -0.783065140247345, -1.428216814994812, 0.1835576295852661, -0.017789334058761597, 0.8585725426673889, 0.5570194721221924, 0.013738420791924, 0.13818328082561493, 0.20349808037281036, -0.0677247941493988, 0.5425571799278259, -0.06561991572380066, -0.708438515663147, -0.025765178725123405, 0.41404932737350464, 0.008081530220806599, 0.3437124788761139, 0.41783905029296875, -0.1746973693370819, -0.2820255160331726, 0.618125319480896, 0.557868242263794, 1.035829782485962, -0.1321527063846588, -0.015029647387564182, -0.06800305098295212, -0.22240033745765686, -0.36971184611320496, 0.08969305455684662, 0.5259276032447815, 0.3407500386238098, -0.21013878285884857, 0.6391003131866455, 0.09345454722642899, 0.6603360176086426, -0.13550220429897308, 0.13113364577293396, 0.08241010457277298, 0.306855708360672, 0.8028063178062439, -0.7324735522270203, 0.5164955854415894, -0.31225866079330444, -0.6612350940704346, 0.27981802821159363, -0.4218570291996002, -0.9050923585891724, 1.4042738676071167, -0.09001341462135315, 0.12367356568574905, -0.7106544375419617, 0.21809950470924377, 0.7102001309394836, 0.01138906180858612, 0.1298302412033081, 0.7588566541671753, 0.7935003042221069, -0.07289796322584152, -0.06862033158540726, -0.22241206467151642, 0.5163872838020325, -0.06819649040699005, 0.34480464458465576, -0.44279104471206665, 0.04675130546092987, -0.477855384349823, -0.1277879774570465, 0.008280555717647076, 0.34289783239364624, -0.37781211733818054, -0.17721377313137054, 0.7687997817993164, -0.47331392765045166, 0.7722886800765991, 0.21865010261535645, 0.19313642382621765, -0.6774762272834778, -1.2393730878829956, 0.6312505006790161, 0.12275184690952301, 0.09960369765758514, 0.09992799907922745, -0.19005028903484344, -0.156041219830513, -0.10265631973743439, 0.18103726208209991, 0.17452220618724823, -0.4235355257987976, -0.10914351046085358, 0.8210529088973999, 0.09848517924547195, 0.1008489727973938, 0.48531126976013184, -1.579073429107666, 0.47329476475715637, 0.5979273319244385, -0.3655267059803009, 0.24899591505527496, -0.7582002282142639, 0.09763026982545853, 0.3844051957130432, -0.2052806168794632, -0.21253147721290588, 0.24739320576190948, -0.26824477314949036, -0.9608515501022339, 1.1455349922180176, 0.5047399401664734, -0.5244059562683105, 0.34170764684677124, -0.6618302464485168, -0.08951621502637863, -0.3381122946739197, 0.14695313572883606, 0.07055727392435074, 0.717222273349762, -0.6536104083061218, 0.09107618778944016, 0.7046278119087219, 0.4475661516189575, -0.12576258182525635, 0.3411904573440552, -0.7302418947219849, 0.9246612191200256, -0.4453870952129364, -0.5378549098968506, -0.5298761129379272, 0.21424929797649384, -0.40272870659828186, 0.000590373354498297, 0.1785208284854889, -0.1600678712129593, -0.7785199880599976, 0.3982484042644501, -0.17938025295734406, -1.513051152229309, 0.1707054227590561, 0.353789359331131, 0.19461914896965027, 0.43994301557540894, -0.03034963831305504, -0.2874177098274231, -0.42502298951148987, 0.3916495442390442, -0.14367356896400452, 0.43379536271095276, 0.15873514115810394, 0.49239683151245117, 0.08475720137357712, -0.9366856217384338, -0.01382862962782383, -0.6042263507843018, 0.12032222747802734, -0.6219484806060791, -0.3629854619503021, -0.1306576132774353, -0.6895731091499329, -0.14280788600444794, -0.021367819979786873, -0.40670740604400635, -0.49915608763694763, 0.2941669523715973, 0.33918851613998413, 0.17258448898792267, -0.13329684734344482, -0.4708574712276459, -0.5852841734886169, -0.8726214170455933, 0.14175376296043396, 0.8434944748878479, 0.36835238337516785, 1.7068257331848145, -0.6797453165054321, -0.35868343710899353, 0.6263884902000427, -0.08974793553352356, -0.4814395010471344, -0.8070803880691528, -0.8114815354347229, -0.12361317127943039, -0.21255972981452942, -0.3408607244491577, -0.0927765965461731, -0.18904723227024078, -0.12705621123313904, 0.19621092081069946, -0.15481296181678772, -0.4509766101837158, -0.2974657714366913, -0.06319610029459, 0.6256510615348816, -0.5709429979324341, -1.6896816492080688, -0.6298220753669739, 0.3308682441711426, -0.3233761787414551, 0.024044999852776527, 1.1300703287124634, -0.4430484175682068, -0.8143961429595947, -1.0549410581588745, 0.18672633171081543, -1.1241765022277832, 0.5151846408843994, -0.41852477192878723, 0.21352697908878326, -0.373629093170166, 0.23685501515865326, 0.6886549592018127, -0.28273168206214905, -0.04134520888328552, -0.6346692442893982, 0.46952351927757263, -0.996688187122345, -0.4311109781265259, -0.34559547901153564, 0.5576220750808716, -0.48568350076675415, 0.7911686897277832, 0.1260855346918106, -0.4214090406894684, 0.355494886636734, -0.18749122321605682, 0.32657280564308167, 0.9986037015914917, -0.7568806409835815, -0.26827675104141235, 0.7716207504272461, -0.2575308680534363, 0.7603334784507751, -0.3813697397708893, -0.5717049837112427, 0.5588721632957458, -0.3644164800643921, -0.4019005596637726, -1.0284162759780884, 0.1821647733449936, -0.6543459892272949, -0.348237544298172, 0.38988789916038513, -0.7555890083312988, -0.06637478619813919, -0.10954003781080246, 0.4849023222923279, 0.12780144810676575, -0.4793679714202881, -0.792290449142456, -0.2691197395324707, -0.7162640690803528, -0.20687337219715118, -0.2705118954181671, -0.8285531401634216, 0.07362494617700577, -0.05774721875786781, 0.03640545904636383, 0.7181563377380371, -0.8355211019515991, 0.29578542709350586, 1.2994489669799805, -0.14052096009254456, -0.438920795917511, -1.0131149291992188, 0.11163873970508575, -0.061945587396621704, -0.00848361011594534, -0.3095645606517792, -0.7630980014801025, -0.2455822378396988, -0.29901283979415894, -0.8545909523963928, -1.0084654092788696, 0.3130161166191101, 0.17482726275920868, 1.271935224533081, -0.4642466604709625, 0.5762917399406433, 0.013354443944990635, 0.14322969317436218, -0.7255604267120361, 1.0521544218063354, 0.12059435248374939, -0.3187575936317444, 0.7070898413658142, 0.055145155638456345, -0.4996209740638733, 0.467449426651001, -0.3858455717563629, -0.7047856450080872, -0.25359293818473816, 0.9633126854896545, 0.011672756634652615, -0.44508057832717896, 1.0012301206588745, 0.3664306402206421, 0.29387882351875305, -0.5709168314933777, -0.3018397390842438, 0.35780319571495056, -0.30288371443748474, -0.7454809546470642, -0.24836212396621704, 0.012907544150948524, 0.24457573890686035, -0.1338043510913849, 0.14836850762367249, -0.6712419986724854, -0.2632633149623871, 0.9592024087905884, -0.09916321188211441, -0.733893871307373, 0.618464469909668, 0.5453699827194214, -0.10450036823749542, 0.06838315725326538, -0.7512381076812744, 0.45656341314315796, -0.013456618413329124, -0.14288966357707977, 0.3682425916194916, 0.2890106737613678, -0.2046298384666443, 0.5083215236663818, 0.4013992249965668, 1.0935386419296265, -0.479035884141922, -0.24689623713493347, 0.6133164167404175, 0.14092011749744415, -0.36957618594169617, -0.13394270837306976, 0.6973139643669128, -0.196162611246109, 0.8578710556030273, -0.4432680010795593, 0.24447453022003174, 0.5855545997619629, 0.4822157621383667, -0.24576547741889954, -0.9083009958267212, 0.32631874084472656, -0.9491044878959656, -0.2595677077770233, -0.19684697687625885, -0.6924645900726318, 0.019424453377723694, 0.7503262758255005, -0.737716794013977, -0.12255918234586716, 0.27568620443344116, 0.6025391817092896, -1.134385347366333, 0.21510814130306244, -0.33187949657440186, 0.1261415034532547, -0.5318054556846619, -0.1451246738433838, 0.525374710559845, -0.48716384172439575, -0.30161795020103455, 0.2953949570655823, 0.40775173902511597, 0.6613409519195557, 0.3440174162387848, -0.042244233191013336, 0.20542986690998077, 0.40245044231414795, -0.2367333471775055, 0.23095400631427765, -0.49425336718559265, 0.8623100519180298, 0.4331407845020294, 0.4607883095741272, 0.5560929775238037, -0.6332882642745972, -0.13387702405452728, 0.3265198767185211, 0.4038580060005188, -0.9240880608558655, -0.19357678294181824, 0.7647299766540527, 0.02439691498875618, 0.9479659199714661, -0.6732637286186218, 0.5014368891716003, -1.0372846126556396, -0.6773430705070496, 0.24859999120235443, 0.14925403892993927, -0.9131075739860535, 0.49349653720855713, 0.9804774522781372, 1.6252753734588623, 0.2483268678188324, 0.0614958293735981, -0.1262485682964325, 0.690987229347229, -0.0008742179488763213, 0.06461376696825027, 0.045698072761297226, -0.266830176115036, -0.009069304913282394, -1.1741119623184204, -0.24929864704608917, 0.6341133713722229, -0.33871403336524963, 0.05865710601210594, -0.3021535873413086, -0.30584967136383057, -0.45679980516433716, 0.2333381026983261, 0.9372268319129944, -0.05883011594414711, 0.4392399489879608, -0.33497437834739685, -0.023390719667077065, 0.18477901816368103, -0.5104859471321106, -0.30435216426849365, -0.24878589808940887, -0.742681622505188, 0.21817530691623688, -0.03793448582291603, 0.8570224046707153, 0.413526326417923, -0.7006863355636597, 0.29500994086265564, 0.6638681292533875, 0.6859912872314453, 0.17960631847381592, 0.4604029953479767, -0.03444211184978485, 0.27280423045158386, -1.1855106353759766, -0.2809278964996338, -0.21664416790008545, 0.12037540227174759, -1.5877288579940796, -0.5308995842933655, 0.22557346522808075, 0.4848705232143402, 0.01121173519641161, -0.17388348281383514, -1.5394304990768433, 0.25244373083114624, 0.550010621547699, 0.07660603523254395, -0.824274480342865, 0.8019675016403198, -0.29613518714904785, 0.105644591152668, -0.588238537311554, -0.1885804533958435, 0.18303225934505463, 0.5549605488777161, 0.19044815003871918, 0.11255525797605515, -0.3817206919193268, 0.32789668440818787, 0.5075958967208862, -0.6300833225250244, 0.9909480810165405, -0.13057838380336761, 0.41782277822494507, 0.39863839745521545, -0.3867190182209015, 0.07498989999294281, 0.3350757360458374, 0.4966261386871338, 0.19113661348819733, -0.836155116558075, 0.8771525621414185, 0.06450946629047394, -0.4349217414855957, 0.02752833627164364, 1.2296782732009888, -0.14117315411567688, 0.043505433946847916, 0.30366143584251404, -1.3453289270401, 0.7988068461418152, -0.9125771522521973, -0.20792408287525177, -0.20128820836544037, 0.20223525166511536, -0.15268956124782562, 0.4270166754722595, -1.0012307167053223, 0.5946698188781738, -0.004532383289188147, -0.652448296546936, -0.19670197367668152, 0.5888553261756897, 0.5143828392028809, 0.27058055996894836, 0.5015372633934021, -0.05742299184203148, 0.30931615829467773, 0.4595007598400116, 0.8909088373184204, -0.11289623379707336, 0.12857253849506378, 0.04980872571468353, 0.19623295962810516, 0.47918254137039185, -0.05836416408419609, -0.36367911100387573, 0.32419732213020325, -0.08906115591526031, -1.2424712181091309, 0.6249502897262573, 0.05221559852361679, -0.8991256356239319, 0.8206058740615845, -0.11495763808488846, -0.5941396355628967, -0.7746909260749817, 0.46640992164611816, -0.450714111328125, 0.27889010310173035, 0.13956153392791748, -0.6705571413040161, -0.38662800192832947, 0.0792415589094162, -0.7241666316986084, 0.24155065417289734, 0.44296109676361084, 1.0124013423919678, -0.5186165571212769, 1.744384765625, 1.0896339416503906, 0.6599395871162415, 0.19218236207962036, 0.28277817368507385, 0.5627049207687378, 0.10704862326383591, 0.153232142329216, -0.41821426153182983, -0.2648054361343384, -0.3989398181438446, -1.4773709774017334, -0.2665596306324005, -0.08519746363162994, 0.049164917320013046, -0.2530341148376465, 0.26442399621009827, 0.20795169472694397, -0.44227853417396545, 0.3628946542739868, 1.4343286752700806, -0.13167713582515717, -0.17252382636070251, -0.20356304943561554, 0.35588309168815613, -1.10452401638031, 0.1679701805114746, -0.8607462644577026, 0.3282575011253357, -0.6792166233062744, -1.0339592695236206, -0.09535010904073715, -0.7306499481201172, -0.5811149477958679, -0.509468138217926, 0.13743464648723602, -0.3536441922187805, 0.48024845123291016, 0.4367203414440155, 0.44211313128471375, 0.21669964492321014, -0.7337697744369507, 0.358882874250412, 0.9334774613380432, 0.3170958459377289, -0.2178860604763031, 1.3486136198043823, 0.15993063151836395, 0.4365067183971405, -0.21948286890983582, 0.19954895973205566, 0.08906236290931702, 0.15338219702243805, 0.012226886115968227, -0.2712203860282898, 0.08877304941415787, -0.7060502767562866, -0.7959313988685608, 0.09466056525707245, 0.6635912656784058, -0.03456083685159683, -1.0250537395477295, -0.9385319352149963, 0.1812409907579422, -0.7444098591804504, 0.48693785071372986, 0.07111863791942596, 1.0100536346435547, -0.4594113528728485, -0.2127605378627777, -0.346859872341156, -0.2563474178314209, 3.8653440475463867, 1.3155608177185059, 0.3009764850139618, -0.3603475093841553, 0.49658897519111633, 0.40477338433265686, 0.498630166053772, 0.41815608739852905, 0.6271349191665649, 0.5707221627235413, 0.17334169149398804, -0.32502031326293945, 0.053332142531871796, -0.12374195456504822, -0.40554744005203247, 0.053758103400468826, -0.7623986005783081, -0.09452275931835175, -0.8919678330421448, -0.8441671133041382, -0.5128089785575867, 0.34579524397850037, -0.1357172578573227, -0.13474248349666595, 0.46801382303237915, -0.5481060743331909, 0.05573832616209984, 0.08240458369255066, -0.17622922360897064, -0.3352280557155609, 0.2985759377479553, -1.0060003995895386, 0.8377681374549866, 0.27171972393989563, -0.26809370517730713, 0.34139224886894226, -0.1886918991804123, -0.6264660954475403, -0.173348531126976, 0.20237796008586884, -0.21934421360492706, -0.054699867963790894, -0.1778506487607956, -0.10738308727741241, -0.576119065284729, 0.9447216987609863, 0.03187975659966469, 0.49869850277900696, 0.8128238320350647, -0.9748319387435913, 0.3584250509738922, -0.35056746006011963, 0.8156034350395203, -0.6393274068832397, -0.5667492747306824, -0.43956470489501953, -0.40846750140190125, -0.6948490142822266, -0.2514420449733734, 0.24575066566467285, -0.2581484615802765, 0.5731927156448364, 0.17829665541648865, 0.17297305166721344, -0.0692002922296524, 0.5523715615272522, -0.005742976441979408, -0.10662650316953659, -0.7429659962654114, 0.2097257375717163, 0.0015980320749804378, -0.3174244165420532, -0.2168918401002884, -0.5724154114723206, 0.23046596348285675, 0.5611544251441956, -0.07965058833360672, 1.0154500007629395, 0.01454969123005867, -0.23341511189937592, -0.8880531787872314, -0.1315888911485672, -0.40887558460235596, 0.05270387604832649, 0.5552204251289368, 0.6720708608627319, -0.21147112548351288, 0.9273583889007568, -0.8234554529190063, 0.5715386867523193, 0.2879490852355957, 0.6679007411003113, 0.4064158797264099, -0.29225483536720276, -0.43003353476524353]\n"]}],"source":["print(embeddings[0])"]},{"cell_type":"markdown","metadata":{"id":"-PnV9lAXZw9a"},"source":["**Create a Vector DB and persist on disk**\n"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"KZagoXUQPjye","executionInfo":{"status":"ok","timestamp":1729979808368,"user_tz":240,"elapsed":161,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["!rm -rf \"/content/research_papers_db\" #replace path to db"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"kRYfcrsHUxyZ","executionInfo":{"status":"ok","timestamp":1729979813390,"user_tz":240,"elapsed":5024,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["from langchain_chroma import Chroma\n","\n","# create vector DB of docs and embeddings - takes < 30s on Colab\n","chroma_db = Chroma.from_documents(documents=chunked_docs,\n","                                  collection_name='research_papers_chroma_db',\n","                                  embedding=openai_embed_model,\n","                                  # need to set the distance function to cosine else it uses euclidean by default\n","                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n","                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n","                                  persist_directory=\"/content/research_papers_db\")"]},{"cell_type":"markdown","metadata":{"id":"9ju_zBIj1Zsb"},"source":["**Load Vector DB from disk**\n","\n"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"pNvj0dDH1WDg","executionInfo":{"status":"ok","timestamp":1729980013557,"user_tz":240,"elapsed":178,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["# load from disk\n","research_papers_chroma_db = Chroma(persist_directory=\"/content/research_papers_db\",\n","                   collection_name='research_papers_chroma_db',\n","                   embedding_function=openai_embed_model)"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NFC3uPqYop0a","executionInfo":{"status":"ok","timestamp":1729980015958,"user_tz":240,"elapsed":205,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"8e1cfa79-9a9b-456c-8ed5-759e8bc267e1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<langchain_chroma.vectorstores.Chroma at 0x7e640e3184f0>"]},"metadata":{},"execution_count":69}],"source":["research_papers_chroma_db"]},{"cell_type":"markdown","metadata":{"id":"UVpAn6nuQm5U"},"source":["### Experiment with different retrieval stratagies"]},{"cell_type":"markdown","metadata":{"id":"aIGjT4xQG02J"},"source":["**ContexualCompressionretriever**"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"zSRG6upbftaS","executionInfo":{"status":"ok","timestamp":1729980032113,"user_tz":240,"elapsed":155,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["from langchain.retrievers.document_compressors import LLMChainFilter\n","from langchain.retrievers import ContextualCompressionRetriever"]},{"cell_type":"code","execution_count":71,"metadata":{"id":"8taCb8F5qHuZ","executionInfo":{"status":"ok","timestamp":1729980034030,"user_tz":240,"elapsed":190,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["# simple cosine distance based retriever\n","similarity_retriever = research_papers_chroma_db.as_retriever(search_type=\"similarity\",\n","                                              search_kwargs={\"k\": 3})\n","\n","#  decides which of the initially retrieved documents to filter out and which ones to return\n","_filter = LLMChainFilter.from_llm(llm=chatgpt)\n","\n","# retrieves the documents similar to query and then applies the filter\n","compression_retriever = ContextualCompressionRetriever(\n","    base_compressor=_filter, base_retriever=similarity_retriever\n",")"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ErDmz2Hcqxom","executionInfo":{"status":"ok","timestamp":1729980037036,"user_tz":240,"elapsed":1543,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"8cc60279-2df5-4278-b4d7-943371645132"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(metadata={'author': '', 'creationDate': 'D:20240410211143Z', 'creator': 'LaTeX with hyperref', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20240410211143Z', 'page': 13, 'producer': 'pdfTeX-1.40.25', 'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'subject': '', 'title': '', 'total_pages': 15, 'trapped': ''}, page_content='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\\nFull attentions for head 5. Bottom: Isolated attentions from just the word its for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14'),\n"," Document(metadata={'author': '', 'creationDate': 'D:20240410211143Z', 'creator': 'LaTeX with hyperref', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20240410211143Z', 'page': 3, 'producer': 'pdfTeX-1.40.25', 'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'subject': '', 'title': '', 'total_pages': 15, 'trapped': ''}, page_content='Scaled Dot-Product Attention\\nMulti-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1\\nScaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V ) = softmax(QKT\\ndk\\n)V\\n(1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof\\n1\\ndk . Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by\\n1\\ndk .\\n3.2.2\\nMulti-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,')]"]},"metadata":{},"execution_count":72}],"source":["query = \"What attention mechanisms were used in the Attention paper?\"\n","docs = compression_retriever.invoke(query)\n","docs"]},{"cell_type":"markdown","metadata":{"id":"ZK-koWtwG7o9"},"source":["**MultiQueryRetriever**"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"_5pYI7SEqxr_","executionInfo":{"status":"ok","timestamp":1729980051056,"user_tz":240,"elapsed":185,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["from langchain.retrievers.multi_query import MultiQueryRetriever\n","# Set logging for the queries\n","import logging\n","\n","similarity_retriever = research_papers_chroma_db.as_retriever(search_type=\"similarity\",\n","                                              search_kwargs={\"k\": 3})\n","\n","mq_retriever = MultiQueryRetriever.from_llm(\n","    retriever=similarity_retriever, llm=chatgpt\n",")\n","\n","logging.basicConfig()\n","# so we can see what queries are generated by the LLM\n","logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LGUnctn7qxut","executionInfo":{"status":"ok","timestamp":1729980054285,"user_tz":240,"elapsed":1862,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"15737cc1-1487-4b58-b981-31686c02f810"},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:langchain.retrievers.multi_query:Generated queries: ['What types of attention mechanisms are discussed in the original Attention paper?  ', 'Which attention mechanisms are introduced in the foundational Attention paper?  ', 'Can you list the attention mechanisms that were proposed in the Attention paper?']\n"]},{"output_type":"execute_result","data":{"text/plain":["[Document(metadata={'author': '', 'creationDate': 'D:20240410211143Z', 'creator': 'LaTeX with hyperref', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20240410211143Z', 'page': 12, 'producer': 'pdfTeX-1.40.25', 'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'subject': '', 'title': '', 'total_pages': 15, 'trapped': ''}, page_content='Attention Visualizations\\nInput-Input Layer5\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb making, completing the phrase making...more difficult. Attentions here shown only for\\nthe word making. Different colors represent different heads. Best viewed in color.\\n13'),\n"," Document(metadata={'author': '', 'creationDate': 'D:20240410211143Z', 'creator': 'LaTeX with hyperref', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20240410211143Z', 'page': 13, 'producer': 'pdfTeX-1.40.25', 'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'subject': '', 'title': '', 'total_pages': 15, 'trapped': ''}, page_content='Input-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\\nFull attentions for head 5. Bottom: Isolated attentions from just the word its for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14'),\n"," Document(metadata={'author': '', 'creationDate': 'D:20240410211143Z', 'creator': 'LaTeX with hyperref', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20240410211143Z', 'page': 3, 'producer': 'pdfTeX-1.40.25', 'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'subject': '', 'title': '', 'total_pages': 15, 'trapped': ''}, page_content='Scaled Dot-Product Attention\\nMulti-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1\\nScaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V ) = softmax(QKT\\ndk\\n)V\\n(1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof\\n1\\ndk . Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by\\n1\\ndk .\\n3.2.2\\nMulti-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,'),\n"," Document(metadata={'author': '', 'creationDate': 'D:20240410211143Z', 'creator': 'LaTeX with hyperref', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20240410211143Z', 'page': 10, 'producer': 'pdfTeX-1.40.25', 'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'subject': '', 'title': '', 'total_pages': 15, 'trapped': ''}, page_content='the limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[16] ukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n[17] ukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[23] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n11')]"]},"metadata":{},"execution_count":74}],"source":["query = \"What attention mechanisms were used in the Attention paper?\"\n","docs = mq_retriever.invoke(query)\n","docs"]},{"cell_type":"markdown","metadata":{"id":"9YK8BBMBAU9o"},"source":["**Chained Retrieval Pipeline**"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"UgZ4eMFc2GgI","executionInfo":{"status":"ok","timestamp":1729980060085,"user_tz":240,"elapsed":3363,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n","from langchain.retrievers.document_compressors import CrossEncoderReranker\n","\n","# Retriever 1 - simple cosine distance based retriever\n","similarity_retriever = research_papers_chroma_db.as_retriever(search_type=\"similarity\",\n","                                              search_kwargs={\"k\": 5})\n","\n","#  decides which of the initially retrieved documents to filter out and which ones to return\n","_filter = LLMChainFilter.from_llm(llm=chatgpt)\n","# Retriever 2 - retrieves the documents similar to query and then applies the filter\n","compressor_retriever = ContextualCompressionRetriever(\n","    base_compressor=_filter, base_retriever=similarity_retriever\n",")\n","\n","# download an open-source reranker model - BAAI/bge-reranker-v2-m3\n","reranker = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-large\")\n","reranker_compressor = CrossEncoderReranker(model=reranker, top_n=3)\n","# Retriever 3 - Uses a Reranker model to rerank retrieval results from the previous retriever\n","final_retriever = ContextualCompressionRetriever(\n","    base_compressor=reranker_compressor, base_retriever=compressor_retriever\n",")"]},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"8dVz4JGVBQTO","executionInfo":{"status":"ok","timestamp":1729980066771,"user_tz":240,"elapsed":3146,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"a6f81101-7834-4921-961f-ec114c700e95"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Document(metadata={'author': '', 'creationDate': 'D:20240410211143Z', 'creator': 'LaTeX with hyperref', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20240410211143Z', 'page': 3, 'producer': 'pdfTeX-1.40.25', 'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'subject': '', 'title': '', 'total_pages': 15, 'trapped': ''}, page_content='Scaled Dot-Product Attention\\nMulti-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1\\nScaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V ) = softmax(QKT\\ndk\\n)V\\n(1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof\\n1\\ndk . Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by\\n1\\ndk .\\n3.2.2\\nMulti-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,'),\n"," Document(metadata={'author': '', 'creationDate': 'D:20240410211143Z', 'creator': 'LaTeX with hyperref', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20240410211143Z', 'page': 4, 'producer': 'pdfTeX-1.40.25', 'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'subject': '', 'title': '', 'total_pages': 15, 'trapped': ''}, page_content='output values. These are concatenated and once again projected, resulting in the final values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\nMultiHead(Q, K, V ) = Concat(head1, ..., headh)W O\\nwhere headi = Attention(QW Q\\ni , KW K\\ni , V W V\\ni )\\nWhere the projections are parameter matrices W Q\\ni\\nRdmodeldk, W K\\ni\\nRdmodeldk, W V\\ni\\nRdmodeldv\\nand W O Rhdvdmodel.\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3\\nApplications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to ) all values in the input')]"]},"metadata":{},"execution_count":76}],"source":["query = \"What attention mechanisms were used in the Attention paper?\"\n","docs = final_retriever.invoke(query)\n","docs"]},{"cell_type":"markdown","metadata":{"id":"Bfn4Z4Em55bb"},"source":["### QA RAG System\n"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"8Pu5U9HNkl-q","executionInfo":{"status":"ok","timestamp":1729979840082,"user_tz":240,"elapsed":4,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","prompt = \"\"\"You are an assistant for question-answering tasks.\n","            Use the following pieces of retrieved context to answer the question.\n","            If no context is present or if you don't know the answer, just say that you don't know.\n","            Do not make up the answer unless it is there in the provided context.\n","            Give a detailed answer with regard to the question.\n","\n","            Question:\n","            {question}\n","\n","            Context:\n","            {context}\n","\n","            Answer:\n","         \"\"\"\n","\n","prompt_template = ChatPromptTemplate.from_template(prompt)"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"18p2bJahmLX_","executionInfo":{"status":"ok","timestamp":1729979840082,"user_tz":240,"elapsed":3,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["from langchain_core.runnables import RunnablePassthrough\n","\n","def format_docs(docs):\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)\n","\n","qa_rag_chain = (\n","    {\n","        \"context\": (final_retriever\n","                      |\n","                    format_docs),\n","        \"question\": RunnablePassthrough()\n","    }\n","      |\n","    prompt_template\n","      |\n","    chatgpt\n",")"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":135},"id":"W2Ion52G99-A","executionInfo":{"status":"ok","timestamp":1729979841492,"user_tz":240,"elapsed":1413,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"0703d045-6e86-4a5e-cabb-88c8fabe8a5b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Answer:\nI'm sorry, but the context provided does not contain any information about the attention mechanisms used in the Attention paper. Therefore, I cannot provide an answer based on the given context. If you have more specific information or another source, I might be able to help further."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Sources (Top 3 Retrieved Documents):"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":""},"metadata":{}}],"source":["from IPython.display import Markdown, display\n","\n","# Helper function to display answer and sources\n","def display_answer_with_sources(query):\n","    # Run the RAG chain and get the result\n","    result = qa_rag_chain.invoke(query)\n","\n","    # Retrieve the top 3 context documents (the sources)\n","    top_docs = final_retriever.invoke(query)[:3]  # Limit to top 3\n","    sources = format_docs(top_docs)\n","\n","    # Display the generated answer\n","    display(Markdown(f\"### Answer:\\n{result.content}\"))\n","\n","    # Display the sources\n","    display(Markdown(\"### Sources (Top 3 Retrieved Documents):\"))\n","    display(Markdown(sources))\n","\n","# Test query: attention mechanisms in the Attention paper\n","query = \"What attention mechanisms were used in the Attention paper?\"\n","display_answer_with_sources(query)"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118},"id":"hdYPx4g39wpW","executionInfo":{"status":"ok","timestamp":1729979842417,"user_tz":240,"elapsed":929,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"f724a709-8dcb-4837-87c6-f301cfbcfb16"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Answer:\nI don't know."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Sources (Top 3 Retrieved Documents):"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":""},"metadata":{}}],"source":["query = \"What novel approaches did the Gemini paper introduce in LLM training?\"\n","display_answer_with_sources(query)"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118},"id":"QJrm6LeOnTU5","executionInfo":{"status":"ok","timestamp":1729979843787,"user_tz":240,"elapsed":1372,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"0962b66c-9e36-4dea-92ab-784de0f1d0e4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Answer:\nI don't know."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### Sources (Top 3 Retrieved Documents):"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":""},"metadata":{}}],"source":["query = \"What datasets were used for training in the GPT-4 paper?\"\n","display_answer_with_sources(query)"]},{"cell_type":"markdown","metadata":{"id":"xEtBJSZLJCmC"},"source":["## **Implementing Stretch Goal: Advanced Option 3**"]},{"cell_type":"markdown","metadata":{"id":"RXeilff0c9X5"},"source":["### Create a Query Retrieval Grader"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"ubFlSqlMSU99","executionInfo":{"status":"ok","timestamp":1729979843787,"user_tz":240,"elapsed":4,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","from langchain_openai import ChatOpenAI\n","\n","\n","# Data model for LLM output format\n","class GradeDocuments(BaseModel):\n","    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n","    binary_score: str = Field(\n","        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n","    )\n","\n","\n","# LLM for grading\n","llm = chatgpt\n","structured_llm_grader = llm.with_structured_output(GradeDocuments)\n","\n","# Prompt template for grading\n","SYS_PROMPT = \"\"\"You are an expert grader assessing relevance of a retrieved document to a user question.\n","                Follow these instructions for grading:\n","                  - If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant.\n","                  - Your grade should be either 'yes' or 'no' to indicate whether the document is relevant to the question or not.\n","             \"\"\"\n","grade_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", SYS_PROMPT),\n","        (\"human\", \"\"\"Retrieved document:\n","                     {document}\n","\n","                     User question:\n","                     {question}\n","                  \"\"\"),\n","    ]\n",")\n","\n","# Build grader chain\n","doc_grader = (grade_prompt\n","                  |\n","              structured_llm_grader)"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"UuiAlPIbaC0W","executionInfo":{"status":"ok","timestamp":1729979844023,"user_tz":240,"elapsed":239,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["query = \"What attention mechanisms were used in the Attention paper?\"\n","top3_docs = final_retriever.invoke(query)\n","for doc in top3_docs:\n","    print(doc.page_content)\n","    print('GRADE:', doc_grader.invoke({\"question\": query, \"document\": doc.page_content}))\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"4PpFmwNFZ3lt"},"source":["### Build a QA RAG Chain"]},{"cell_type":"code","execution_count":103,"metadata":{"id":"M2uXFNdbZ3mD","executionInfo":{"status":"ok","timestamp":1729981081573,"user_tz":240,"elapsed":201,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["from langchain_core.prompts import ChatPromptTemplate\n","from langchain_openai import ChatOpenAI\n","from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n","from langchain_core.output_parsers import StrOutputParser\n","from operator import itemgetter\n","\n","prompt = \"\"\"You are an assistant for question-answering tasks.\n","            Use the following pieces of retrieved context to answer the question.\n","            If no context is present or if you don't know the answer, just say that you don't know the answer.\n","            Do not make up the answer unless it is there in the provided context.\n","            However, if there are any web search results, always consider them in your response.\n","            Give a detailed answer and to the point answer with regard to the question.\n","\n","            Question:\n","            {question}\n","\n","            Context:\n","            {context}\n","\n","            Answer:\n","         \"\"\"\n","prompt_template = ChatPromptTemplate.from_template(prompt)\n","\n","def format_docs(docs):\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)\n","\n","qa_rag_chain = (\n","    {\n","        \"context\": (itemgetter('context')\n","                        |\n","                    RunnableLambda(format_docs)),\n","        \"question\": itemgetter('question')\n","    }\n","      |\n","    prompt_template\n","      |\n","    chatgpt\n","      |\n","    StrOutputParser()\n",")"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Wj-MZr2eEq8","executionInfo":{"status":"ok","timestamp":1729979844765,"user_tz":240,"elapsed":745,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"c2db724c-99fe-4331-e554-58e6d97b577f"},"outputs":[{"output_type":"stream","name":"stdout","text":["I don't know the answer.\n"]}],"source":["query = \"What attention mechanisms were used in the Attention paper?\"\n","top3_docs = final_retriever.invoke(query)\n","result = qa_rag_chain.invoke(\n","    {\"context\": top3_docs, \"question\": query}\n",")\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"-Fp8Eh0x5bMY"},"source":["### Create a Query Rephraser"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"Mm7T22tmfYWj","executionInfo":{"status":"ok","timestamp":1729979844765,"user_tz":240,"elapsed":2,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["# Prompt template for rewriting\n","SYS_PROMPT = \"\"\"Act as a question re-writer and perform the following task:\n","                 - Convert the following input question to a better version that is optimized for web search.\n","                 - When re-writing, look at the input question and try to reason about the underlying semantic intent / meaning.\n","             \"\"\"\n","re_write_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", SYS_PROMPT),\n","        (\"human\", \"\"\"Here is the initial question:\n","                     {question}\n","\n","                     Formulate an improved question.\n","                  \"\"\",\n","        ),\n","    ]\n",")\n","\n","question_rewriter = (re_write_prompt\n","                        |\n","                       chatgpt\n","                        |\n","                     StrOutputParser())"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"2bGCpLKzhTUr","executionInfo":{"status":"ok","timestamp":1729979845336,"user_tz":240,"elapsed":573,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"8a8fdc26-5022-4327-a4db-0570d657bdad"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'What attention mechanisms are discussed in the original \"Attention is All You Need\" paper?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":50}],"source":["query = \"What attention mechanisms were used in the Attention paper?\"\n","question_rewriter.invoke({\"question\": query})"]},{"cell_type":"markdown","metadata":{"id":"howf-v0ARWbv"},"source":["### Load Web Search Tool"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"Ue8xgu9WpuPi","executionInfo":{"status":"ok","timestamp":1729979845674,"user_tz":240,"elapsed":340,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["from langchain_community.tools.tavily_search import TavilySearchResults\n","\n","tv_search = TavilySearchResults(max_results=3, search_depth='advanced',\n","                                max_tokens=10000)"]},{"cell_type":"markdown","metadata":{"id":"D2N5192vikJR"},"source":["### Build Agentic RAG components\n","\n","Here we will build the key components of our Agentic Corrective RAG System as per the workflow below:\n","\n","![](https://i.imgur.com/uhybMhT.png)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"U5tUXzqPsbQi"},"source":["### Graph State\n"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"_B2EFrwTpuXB","executionInfo":{"status":"ok","timestamp":1729979845675,"user_tz":240,"elapsed":8,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["from typing import List\n","from typing_extensions import TypedDict\n","\n","class GraphState(TypedDict):\n","    \"\"\"\n","    Represents the state of our graph.\n","\n","    Attributes:\n","        question: question\n","        generation: LLM response generation\n","        web_search_needed: flag of whether to add web search - yes or no\n","        documents: list of context documents\n","    \"\"\"\n","\n","    question: str\n","    generation: str\n","    web_search_needed: str\n","    documents: List[str]"]},{"cell_type":"markdown","metadata":{"id":"qXfVLhOWtHJJ"},"source":["### Retrieve function for retrieval from Vector DB"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"W0rVVBGDpuYw","executionInfo":{"status":"ok","timestamp":1729979845675,"user_tz":240,"elapsed":7,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["def retrieve(state):\n","    \"\"\"\n","    Retrieve documents\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): New key added to state, documents - that contains retrieved context documents\n","    \"\"\"\n","    print(\"---RETRIEVAL FROM VECTOR DB---\")\n","    question = state[\"question\"]\n","\n","    # Retrieval\n","    documents = final_retriever.invoke(question)\n","    return {\"documents\": documents, \"question\": question}"]},{"cell_type":"markdown","metadata":{"id":"lpOsUnzn6Yo1"},"source":["### Grade documents"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"NI20nh1DtTwJ","executionInfo":{"status":"ok","timestamp":1729979845675,"user_tz":240,"elapsed":7,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["def grade_documents(state):\n","    \"\"\"\n","    Determines whether the retrieved documents are relevant to the question\n","    by using an LLM Grader.\n","\n","    If any document are not relevant to question or documents are empty - Web Search needs to be done\n","    If all documents are relevant to question - Web Search is not needed\n","    Helps filtering out irrelevant documents\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): Updates documents key with only filtered relevant documents\n","    \"\"\"\n","\n","    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","\n","    # Score each doc\n","    filtered_docs = []\n","    web_search_needed = \"Yes\"\n","    if documents:\n","        for d in documents:\n","            score = doc_grader.invoke(\n","                {\"question\": question, \"document\": d.page_content}\n","            )\n","            grade = score.binary_score\n","            if grade == \"yes\":\n","                print(\"---GRADE: DOCUMENT RELEVANT---\")\n","                filtered_docs.append(d)\n","                web_search_needed = \"No\"\n","            else:\n","                print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n","    else:\n","        print(\"---NO DOCUMENTS RETRIEVED---\")\n","\n","    return {\"documents\": filtered_docs, \"question\": question, \"web_search_needed\": web_search_needed}"]},{"cell_type":"markdown","metadata":{"id":"fj1jk8C16hhE"},"source":["### Rewrite query"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"Xw_iVhvWuSG-","executionInfo":{"status":"ok","timestamp":1729979845675,"user_tz":240,"elapsed":7,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["def rewrite_query(state):\n","    \"\"\"\n","    Rewrite the query to produce a better question.\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): Updates question key with a re-phrased or re-written question\n","    \"\"\"\n","\n","    print(\"---REWRITE QUERY---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","\n","    # Re-write question\n","    better_question = question_rewriter.invoke({\"question\": question})\n","    return {\"documents\": documents, \"question\": better_question}"]},{"cell_type":"markdown","metadata":{"id":"HMogEnhT7Icn"},"source":["### Web Search"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"YM7f6AyCvUP_","executionInfo":{"status":"ok","timestamp":1729981039444,"user_tz":240,"elapsed":180,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["from langchain.schema import Document\n","\n","def web_search(state):\n","    \"\"\"\n","    Web search based on the re-written question.\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): Updates documents key with appended web results\n","    \"\"\"\n","\n","    print(\"---WEB SEARCH---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","\n","    # Web search\n","    docs = tv_search.invoke(question)\n","    print(\"---WEB SEARCH RESULTS---\")\n","    for doc in docs:\n","        print(doc[\"content\"])\n","\n","    for d in docs:\n","        documents.append(Document(page_content=d[\"content\"]))\n","\n","    # web_results = \"\\n\\n\".join([d[\"content\"] for d in docs])\n","    # web_results = Document(page_content=web_results)\n","    # documents.append(web_results)\n","\n","    return {\"documents\": documents, \"question\": question}"]},{"cell_type":"markdown","metadata":{"id":"ruTBxSkm7R2R"},"source":["### Generate Answer"]},{"cell_type":"code","execution_count":85,"metadata":{"id":"MemqMTolwLhA","executionInfo":{"status":"ok","timestamp":1729980624245,"user_tz":240,"elapsed":184,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["def generate_answer(state):\n","    \"\"\"\n","    Generate answer from context document using LLM\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        state (dict): New key added to state, generation, that contains LLM generation\n","    \"\"\"\n","    print(\"---GENERATE ANSWER---\")\n","    question = state[\"question\"]\n","    documents = state[\"documents\"]\n","\n","    # Ensure there is context before attempting to generate an answer\n","    if documents:\n","        generation = qa_rag_chain.invoke({\"context\": documents, \"question\": question})\n","    else:\n","        generation = \"I don't know the answer. The context provided does not contain information to answer the question.\"\n","\n","    return {\"documents\": documents, \"question\": question, \"generation\": generation}"]},{"cell_type":"markdown","metadata":{"id":"-9zcEgiu8HRY"},"source":["### Decide to Generate"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"Zi3GzDLRv3Nf","executionInfo":{"status":"ok","timestamp":1729979845675,"user_tz":240,"elapsed":6,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["def decide_to_generate(state):\n","    \"\"\"\n","    Determines whether to generate an answer, or re-generate a question.\n","\n","    Args:\n","        state (dict): The current graph state\n","\n","    Returns:\n","        str: Binary decision for next node to call\n","    \"\"\"\n","\n","    print(\"---ASSESS GRADED DOCUMENTS---\")\n","    web_search_needed = state[\"web_search_needed\"]\n","\n","    if web_search_needed == \"Yes\":\n","        # All documents have been filtered check_relevance\n","        # We will re-generate a new query\n","        print(\"---DECISION: SOME or ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, REWRITE QUERY---\")\n","        return \"rewrite_query\"\n","    else:\n","        # We have relevant documents, so generate answer\n","        print(\"---DECISION: GENERATE RESPONSE---\")\n","        return \"generate_answer\""]},{"cell_type":"markdown","metadata":{"id":"EpjPx4v89BVV"},"source":["### Build the Agent Graph"]},{"cell_type":"code","execution_count":104,"metadata":{"id":"F24b6qm_yhnE","executionInfo":{"status":"ok","timestamp":1729981093839,"user_tz":240,"elapsed":188,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":["from langgraph.graph import END, StateGraph\n","\n","agentic_rag = StateGraph(GraphState)\n","\n","# Define the nodes\n","agentic_rag.add_node(\"retrieve\", retrieve)  # retrieve\n","agentic_rag.add_node(\"grade_documents\", grade_documents)  # grade documents\n","agentic_rag.add_node(\"rewrite_query\", rewrite_query)  # transform_query\n","agentic_rag.add_node(\"web_search\", web_search)  # web search\n","agentic_rag.add_node(\"generate_answer\", generate_answer)  # generate answer\n","\n","# Build graph\n","agentic_rag.set_entry_point(\"retrieve\")\n","agentic_rag.add_edge(\"retrieve\", \"grade_documents\")\n","agentic_rag.add_conditional_edges(\n","    \"grade_documents\",\n","    decide_to_generate,\n","    {\"rewrite_query\": \"rewrite_query\", \"generate_answer\": \"generate_answer\"},\n",")\n","agentic_rag.add_edge(\"rewrite_query\", \"web_search\")\n","agentic_rag.add_edge(\"web_search\", \"generate_answer\")\n","agentic_rag.add_edge(\"generate_answer\", END)\n","\n","# Compile\n","agentic_rag = agentic_rag.compile()"]},{"cell_type":"code","execution_count":105,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":647},"id":"o7s8SElUvnHD","executionInfo":{"status":"ok","timestamp":1729981097697,"user_tz":240,"elapsed":223,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"a13a98be-74af-4a9b-8a86-22f5bc09b298"},"outputs":[{"output_type":"display_data","data":{"image/jpeg":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}}],"source":["from IPython.display import Image, display, Markdown\n","\n","display(Image(agentic_rag.get_graph().draw_mermaid_png()))"]},{"cell_type":"markdown","metadata":{"id":"pXW3yX7s9MMY"},"source":["### Test the Agentic CRAG System"]},{"cell_type":"code","execution_count":108,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tgny4kCM0OrS","executionInfo":{"status":"ok","timestamp":1729981133583,"user_tz":240,"elapsed":6216,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"4433e535-da6f-468c-a64b-c993d01198c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["---RETRIEVAL FROM VECTOR DB---\n","---CHECK DOCUMENT RELEVANCE TO QUESTION---\n","---GRADE: DOCUMENT RELEVANT---\n","---GRADE: DOCUMENT RELEVANT---\n","---GRADE: DOCUMENT NOT RELEVANT---\n","---ASSESS GRADED DOCUMENTS---\n","---DECISION: GENERATE RESPONSE---\n","---GENERATE ANSWER---\n"]}],"source":["query = \"What attention mechanisms were used in the Attention paper?\"\n","response = agentic_rag.invoke({\"question\": query})"]},{"cell_type":"code","execution_count":109,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"9Y7Q-KAF2oqA","executionInfo":{"status":"ok","timestamp":1729981134670,"user_tz":240,"elapsed":198,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"bff3b4c7-cab3-4455-dcdb-767967ad7c9c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"The Attention paper, specifically the Transformer model, utilizes two main attention mechanisms: Scaled Dot-Product Attention and Multi-Head Attention.\n\n1. **Scaled Dot-Product Attention**: This mechanism involves computing the dot products of the query with all keys, dividing each by the square root of the dimension of the keys (\\(\\sqrt{d_k}\\)), and applying a softmax function to obtain the weights on the values. This scaling factor is used to counteract the effect of large dot products, which can push the softmax function into regions with extremely small gradients.\n\n2. **Multi-Head Attention**: This mechanism involves running several attention layers, or \"heads,\" in parallel. Each head performs the attention function on different linear projections of the queries, keys, and values. The outputs of these heads are then concatenated and projected to form the final output. Multi-head attention allows the model to attend to information from different representation subspaces at different positions, enhancing the model's ability to capture various aspects of the input data.\n\nThese mechanisms are employed in different ways within the Transformer model, such as in encoder-decoder attention layers, encoder self-attention layers, and decoder self-attention layers, each serving specific roles in processing the input and output sequences."},"metadata":{}}],"source":["display(Markdown(response['generation']))"]},{"cell_type":"code","execution_count":110,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVSzCfgb0q4q","executionInfo":{"status":"ok","timestamp":1729981137361,"user_tz":240,"elapsed":160,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"3c2c5b78-d44f-413d-99f0-510cdf652353"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'question': 'What attention mechanisms were used in the Attention paper?',\n"," 'generation': 'The Attention paper, specifically the Transformer model, utilizes two main attention mechanisms: Scaled Dot-Product Attention and Multi-Head Attention.\\n\\n1. **Scaled Dot-Product Attention**: This mechanism involves computing the dot products of the query with all keys, dividing each by the square root of the dimension of the keys (\\\\(\\\\sqrt{d_k}\\\\)), and applying a softmax function to obtain the weights on the values. This scaling factor is used to counteract the effect of large dot products, which can push the softmax function into regions with extremely small gradients.\\n\\n2. **Multi-Head Attention**: This mechanism involves running several attention layers, or \"heads,\" in parallel. Each head performs the attention function on different linear projections of the queries, keys, and values. The outputs of these heads are then concatenated and projected to form the final output. Multi-head attention allows the model to attend to information from different representation subspaces at different positions, enhancing the model\\'s ability to capture various aspects of the input data.\\n\\nThese mechanisms are employed in different ways within the Transformer model, such as in encoder-decoder attention layers, encoder self-attention layers, and decoder self-attention layers, each serving specific roles in processing the input and output sequences.',\n"," 'web_search_needed': 'No',\n"," 'documents': [Document(metadata={'author': '', 'creationDate': 'D:20240410211143Z', 'creator': 'LaTeX with hyperref', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20240410211143Z', 'page': 3, 'producer': 'pdfTeX-1.40.25', 'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'subject': '', 'title': '', 'total_pages': 15, 'trapped': ''}, page_content='Scaled Dot-Product Attention\\nMulti-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1\\nScaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V ) = softmax(QKT\\ndk\\n)V\\n(1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof\\n1\\ndk . Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by\\n1\\ndk .\\n3.2.2\\nMulti-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,'),\n","  Document(metadata={'author': '', 'creationDate': 'D:20240410211143Z', 'creator': 'LaTeX with hyperref', 'file_path': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'format': 'PDF 1.5', 'keywords': '', 'modDate': 'D:20240410211143Z', 'page': 4, 'producer': 'pdfTeX-1.40.25', 'source': '/content/drive/MyDrive/Agents/Capstone Project/pinnacle_capstone_data/attention_paper.pdf', 'subject': '', 'title': '', 'total_pages': 15, 'trapped': ''}, page_content='output values. These are concatenated and once again projected, resulting in the final values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\nMultiHead(Q, K, V ) = Concat(head1, ..., headh)W O\\nwhere headi = Attention(QW Q\\ni , KW K\\ni , V W V\\ni )\\nWhere the projections are parameter matrices W Q\\ni\\nRdmodeldk, W K\\ni\\nRdmodeldk, W V\\ni\\nRdmodeldv\\nand W O Rhdvdmodel.\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3\\nApplications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to ) all values in the input')]}"]},"metadata":{},"execution_count":110}],"source":["response"]},{"cell_type":"code","execution_count":111,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aAm5ERMM2fFL","executionInfo":{"status":"ok","timestamp":1729981149030,"user_tz":240,"elapsed":7312,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"36943df1-4b02-45cb-a394-be21221dd83e"},"outputs":[{"output_type":"stream","name":"stdout","text":["---RETRIEVAL FROM VECTOR DB---\n","---CHECK DOCUMENT RELEVANCE TO QUESTION---\n","---GRADE: DOCUMENT RELEVANT---\n","---GRADE: DOCUMENT RELEVANT---\n","---ASSESS GRADED DOCUMENTS---\n","---DECISION: GENERATE RESPONSE---\n","---GENERATE ANSWER---\n"]}],"source":["query = \"What novel approaches did the Gemini paper introduce in LLM training?\"\n","response = agentic_rag.invoke({\"question\": query})"]},{"cell_type":"code","execution_count":112,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":318},"id":"CTCcEfNx2w-5","executionInfo":{"status":"ok","timestamp":1729981150343,"user_tz":240,"elapsed":177,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"437a907f-d014-4b04-e40a-c4befb37aaa9"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"The Gemini paper introduced several novel approaches in the training of large language models (LLMs):\n\n1. **Multimodal Training**: The Gemini models are natively multimodal, meaning they are trained jointly across text, image, audio, and video. This approach allows the models to achieve strong capabilities in each domain, setting a new state of the art across a wide range of benchmarks.\n\n2. **Tokenization and Training Strategy**: The number of tokens used to train the largest models was determined following the approach in Hoffmann et al. (2022), while smaller models were trained with significantly more tokens to improve performance for a given inference budget, similar to the approach in Touvron et al. (2023a).\n\n3. **Data Quality and Filtering**: The paper emphasizes the importance of data quality for high-performing models. Quality filters, both heuristic and model-based, were applied to all datasets. Safety filtering was also performed to remove harmful content. The final data mixtures and weights were determined through ablations on smaller models, and training was staged to alter the mixture composition, increasing the weight of domain-relevant data towards the end of training.\n\n4. **Tool Use**: By training LLMs to use tools, the capabilities of the models were greatly expanded beyond their internal knowledge. Tool use was treated as a code generation problem, leveraging the model's strong coding capabilities. This approach allows the model to compose multiple tools in each code block and react to the results of tool execution.\n\nThese approaches collectively contribute to the enhanced performance and capabilities of the Gemini models in various domains."},"metadata":{}}],"source":["display(Markdown(response['generation']))"]},{"cell_type":"code","execution_count":106,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0PH45g2E3Dta","executionInfo":{"status":"ok","timestamp":1729981114847,"user_tz":240,"elapsed":9281,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"0b844548-9836-403e-b813-80203b1a65e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["---RETRIEVAL FROM VECTOR DB---\n","---CHECK DOCUMENT RELEVANCE TO QUESTION---\n","---NO DOCUMENTS RETRIEVED---\n","---ASSESS GRADED DOCUMENTS---\n","---DECISION: SOME or ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, REWRITE QUERY---\n","---REWRITE QUERY---\n","---WEB SEARCH---\n","---WEB SEARCH RESULTS---\n","In this study, we hypothesized that ChatGPT can compose text, tables and figures for a biomedical research paper using two cancer research papers as benchmarks. To test this ... eleven reference articles were utilized to construct ... despite the possibility that the original review paper BRP1 was part of GPT-4's training dataset, the\n","Treatment recommendations were elicited from GPT-4 and evaluated by two board-certified specialty-trained senior orthopedic surgeons. ... and domain-specific training using medical datasets\n","We systematically assessed GPT-4's cell type annotation performance across ten datasets 4,5,6,7,8,9,10,11,12, covering five species and hundreds of tissue and cell types, and including both\n","---GENERATE ANSWER---\n"]}],"source":["query = \"What datasets were used for training in the GPT-4 paper?\"\n","response = agentic_rag.invoke({\"question\": query})"]},{"cell_type":"code","execution_count":107,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"Z6G7ywp53FrO","executionInfo":{"status":"ok","timestamp":1729981116293,"user_tz":240,"elapsed":158,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}},"outputId":"be8c270c-111d-4633-bafd-3b323f1e30ae"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"The provided context does not specify the exact datasets used for training in the GPT-4 research paper. It mentions the use of medical datasets for domain-specific training and the assessment of GPT-4's performance across ten datasets covering various species and cell types, but it does not detail the specific datasets used for the overall training of GPT-4. Therefore, I don't know the answer based on the given context."},"metadata":{}}],"source":["display(Markdown(response['generation']))"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"GT3fGcmbvnjo","executionInfo":{"status":"ok","timestamp":1729979865660,"user_tz":240,"elapsed":8,"user":{"displayName":"Rohith Reddy","userId":"02764363428905860681"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1Uzu_tZSoXPbhyWQ6_Y5umCNW__rIh4pK","authorship_tag":"ABX9TyNtXQ72haxHr5RZH/x6/u7p"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"be16f7f8652248b3ade29e9384d75d46":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da2a358c855b49b28b8ecc506bb8bbdd","IPY_MODEL_d31c267d5b6c44b4973d0656f29afb02","IPY_MODEL_fe69d80aca0b4e488d15f1efcacfd81b"],"layout":"IPY_MODEL_160ac6ee86384dbcbde79031aba8b4f1"}},"da2a358c855b49b28b8ecc506bb8bbdd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_963824d5b57e4ca9a638750da159a036","placeholder":"","style":"IPY_MODEL_91957b0253524e0bbf97d5003b43fec6","value":"modules.json:100%"}},"d31c267d5b6c44b4973d0656f29afb02":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_988971546ac341d4a1783a3d195b7d7e","max":229,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6e1d7a6a81574fdb9e95a2cf07514c31","value":229}},"fe69d80aca0b4e488d15f1efcacfd81b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea69c2ce10a24ba4aa1e99cf6c2930a2","placeholder":"","style":"IPY_MODEL_fdcab46f1e504316a56b12b54808b63a","value":"229/229[00:00&lt;00:00,15.7kB/s]"}},"160ac6ee86384dbcbde79031aba8b4f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"963824d5b57e4ca9a638750da159a036":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91957b0253524e0bbf97d5003b43fec6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"988971546ac341d4a1783a3d195b7d7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e1d7a6a81574fdb9e95a2cf07514c31":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ea69c2ce10a24ba4aa1e99cf6c2930a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdcab46f1e504316a56b12b54808b63a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8acf8fd5ec5d4126b01fec6626a77cde":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed132ee12f654da0ad845b4714e6fd47","IPY_MODEL_63c485b2dd8e4090a51484e1484248a9","IPY_MODEL_8fe64bdec5f14f41a4b3f5b3584c1967"],"layout":"IPY_MODEL_ef86f32e69e34221931e87225e64ba42"}},"ed132ee12f654da0ad845b4714e6fd47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40d1e21bb14742af91ea1eecae02ee52","placeholder":"","style":"IPY_MODEL_64a3607f83ef448da3ccf81c84b8ebe6","value":"config_sentence_transformers.json:100%"}},"63c485b2dd8e4090a51484e1484248a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_382c1463ece24c39876070b2f7b3df80","max":171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6e9c824d83e14326b940f6131452e29e","value":171}},"8fe64bdec5f14f41a4b3f5b3584c1967":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b9f74212a604e659ee6d5dadaebd38f","placeholder":"","style":"IPY_MODEL_5d838d84c621405ca075eea86e1ddf25","value":"171/171[00:00&lt;00:00,12.1kB/s]"}},"ef86f32e69e34221931e87225e64ba42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40d1e21bb14742af91ea1eecae02ee52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64a3607f83ef448da3ccf81c84b8ebe6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"382c1463ece24c39876070b2f7b3df80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e9c824d83e14326b940f6131452e29e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9b9f74212a604e659ee6d5dadaebd38f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d838d84c621405ca075eea86e1ddf25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bcc8b5a83d1347ae990641329bd34291":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_82de1f0380574863a01f0e2c78d4f92a","IPY_MODEL_cafca01490d541c1affbfba39d6384aa","IPY_MODEL_9ed067e11cc94a52b48112b16ba0138b"],"layout":"IPY_MODEL_d2d7c1e7d37c43e4aaed7e0e449480b0"}},"82de1f0380574863a01f0e2c78d4f92a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28a72d2fcb7c48e8b6e53521169e917c","placeholder":"","style":"IPY_MODEL_40bc7da138f84f6486bdb2ddfcccceb5","value":"README.md:100%"}},"cafca01490d541c1affbfba39d6384aa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c206ddb1a3d4cdcb603d7e93b0b28a7","max":113515,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5086f3332cea4eeb8022e0a23a88da17","value":113515}},"9ed067e11cc94a52b48112b16ba0138b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_522c4d012299407c95679ae3d1f417a4","placeholder":"","style":"IPY_MODEL_2cef87aecab845fc9d20ac292ff95d7e","value":"114k/114k[00:00&lt;00:00,3.07MB/s]"}},"d2d7c1e7d37c43e4aaed7e0e449480b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28a72d2fcb7c48e8b6e53521169e917c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40bc7da138f84f6486bdb2ddfcccceb5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c206ddb1a3d4cdcb603d7e93b0b28a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5086f3332cea4eeb8022e0a23a88da17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"522c4d012299407c95679ae3d1f417a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cef87aecab845fc9d20ac292ff95d7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f4f5b9da1ae4982a742b047232d6402":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3b3028b251ad48c9aabf3e5959c31019","IPY_MODEL_d2a63cc3344a4b48b7f9ac4f9928542e","IPY_MODEL_0779c22b040748ad9baab6bd95aec9ec"],"layout":"IPY_MODEL_b447ccd169374d6d9ae6f47f77300088"}},"3b3028b251ad48c9aabf3e5959c31019":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_adac9dd759524b2594e8ea65587352c4","placeholder":"","style":"IPY_MODEL_8691bc7c6a464e7aba44d4eea116aedf","value":"sentence_bert_config.json:100%"}},"d2a63cc3344a4b48b7f9ac4f9928542e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8283a25fe37247339c884fb2088e956d","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45298a9b93ea47c58b1ff0e8a097b4e7","value":53}},"0779c22b040748ad9baab6bd95aec9ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdfc7a173a4041e08b6e88187955cbd8","placeholder":"","style":"IPY_MODEL_ae4500dadf4444cea7ad1b4c554c8ea2","value":"53.0/53.0[00:00&lt;00:00,3.34kB/s]"}},"b447ccd169374d6d9ae6f47f77300088":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adac9dd759524b2594e8ea65587352c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8691bc7c6a464e7aba44d4eea116aedf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8283a25fe37247339c884fb2088e956d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45298a9b93ea47c58b1ff0e8a097b4e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cdfc7a173a4041e08b6e88187955cbd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae4500dadf4444cea7ad1b4c554c8ea2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"00cddbb810564830b147ce4bf0c85d58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b49eeecebdc74cf2b8d4e890a7bb15f3","IPY_MODEL_52ba8515ba204aec93bf5276e21cb87d","IPY_MODEL_47039b89a8034b09a03cbb5ae228e135"],"layout":"IPY_MODEL_c8387d65ad074567a740c6caac9f3b52"}},"b49eeecebdc74cf2b8d4e890a7bb15f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cab96160e70481a8464d01d2a1c5fa1","placeholder":"","style":"IPY_MODEL_5c1b9cc1d354480998e01795e8b76b31","value":"config.json:100%"}},"52ba8515ba204aec93bf5276e21cb87d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4ea8f0d7c42467d9d67e26cc0750d1a","max":677,"min":0,"orientation":"horizontal","style":"IPY_MODEL_74c20b420ac240398778318fbe502097","value":677}},"47039b89a8034b09a03cbb5ae228e135":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d877b0e648144e6f9d3857fbc4642ed4","placeholder":"","style":"IPY_MODEL_423a19fbbdc4465b9fe2ac8fe11d7cf9","value":"677/677[00:00&lt;00:00,41.6kB/s]"}},"c8387d65ad074567a740c6caac9f3b52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cab96160e70481a8464d01d2a1c5fa1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c1b9cc1d354480998e01795e8b76b31":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4ea8f0d7c42467d9d67e26cc0750d1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74c20b420ac240398778318fbe502097":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d877b0e648144e6f9d3857fbc4642ed4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"423a19fbbdc4465b9fe2ac8fe11d7cf9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75684d39258d4abc88c57f6649e05899":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fb045f639b4e4618bc10a94ee1b9bd73","IPY_MODEL_e8cbb8360eb14ab59e1e8d4fcb175e51","IPY_MODEL_ca289490c3e14739907d87a3bd55bdb2"],"layout":"IPY_MODEL_c0a28e01e0154f149470804990737e68"}},"fb045f639b4e4618bc10a94ee1b9bd73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_704fff10e741467187e2ae6cb18af0a9","placeholder":"","style":"IPY_MODEL_5de58da74e994c8f9ce46aa1cf1d9009","value":"model.safetensors:100%"}},"e8cbb8360eb14ab59e1e8d4fcb175e51":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca6757b720134a6c867f3abceb18ebee","max":670328392,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7ea5c3811364a71a4ce9274b9ff7020","value":670328392}},"ca289490c3e14739907d87a3bd55bdb2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_488f061fcdd54cb3917a94a48b0a1bce","placeholder":"","style":"IPY_MODEL_57c9c46ee7594340b55a1e13c12e9db4","value":"670M/670M[01:04&lt;00:00,10.4MB/s]"}},"c0a28e01e0154f149470804990737e68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"704fff10e741467187e2ae6cb18af0a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5de58da74e994c8f9ce46aa1cf1d9009":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca6757b720134a6c867f3abceb18ebee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7ea5c3811364a71a4ce9274b9ff7020":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"488f061fcdd54cb3917a94a48b0a1bce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57c9c46ee7594340b55a1e13c12e9db4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"005b2b2b884f43ca8634d3049ed63916":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0364b012d38643a6b0378065b9a440ca","IPY_MODEL_cf3f2c39b0904c6f85585136ffd63b54","IPY_MODEL_b01725590be74304907020cc9f3637f7"],"layout":"IPY_MODEL_30b312e89df24a2cb0d226935d4f3bff"}},"0364b012d38643a6b0378065b9a440ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b953f8e33e94748ab33fdd24beda50e","placeholder":"","style":"IPY_MODEL_fcb1aa09d6a24c43934e9e8c2f2c433e","value":"tokenizer_config.json:100%"}},"cf3f2c39b0904c6f85585136ffd63b54":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a16d2e96e34844ccbb927c0cebf1d975","max":1242,"min":0,"orientation":"horizontal","style":"IPY_MODEL_996e309bb72447589d93b551b544fc42","value":1242}},"b01725590be74304907020cc9f3637f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a745ebcc29274242a7dafe2e6402d6d7","placeholder":"","style":"IPY_MODEL_9807ed2e705a4ad299643b60f816a6f0","value":"1.24k/1.24k[00:00&lt;00:00,54.3kB/s]"}},"30b312e89df24a2cb0d226935d4f3bff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b953f8e33e94748ab33fdd24beda50e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcb1aa09d6a24c43934e9e8c2f2c433e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a16d2e96e34844ccbb927c0cebf1d975":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"996e309bb72447589d93b551b544fc42":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a745ebcc29274242a7dafe2e6402d6d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9807ed2e705a4ad299643b60f816a6f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1330c8cd9a94e3f9c3e1c0b011d9f25":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2604dae17c584bf6a58ffeda053d11f7","IPY_MODEL_effe2a9aa6204fa1bc4d5b2cea521dd8","IPY_MODEL_ea6778343afd414780f7e93dbf6d5f0b"],"layout":"IPY_MODEL_88bb23e459704147b655aa39304dda06"}},"2604dae17c584bf6a58ffeda053d11f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec113fe92bb54f41958f284d190e07b4","placeholder":"","style":"IPY_MODEL_a99a1037ea4b4640aedc7807922cacd5","value":"vocab.txt:100%"}},"effe2a9aa6204fa1bc4d5b2cea521dd8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb4f271081f14b5a97417414dd2486ed","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b782a39c6624351a92b5197145374ed","value":231508}},"ea6778343afd414780f7e93dbf6d5f0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54e8ecc154a44b378b4c5cc5e66dd9e8","placeholder":"","style":"IPY_MODEL_e8a7246f0c3a4f64b8b5eb995a155b92","value":"232k/232k[00:00&lt;00:00,9.34MB/s]"}},"88bb23e459704147b655aa39304dda06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec113fe92bb54f41958f284d190e07b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a99a1037ea4b4640aedc7807922cacd5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb4f271081f14b5a97417414dd2486ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b782a39c6624351a92b5197145374ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54e8ecc154a44b378b4c5cc5e66dd9e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8a7246f0c3a4f64b8b5eb995a155b92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37eb087c67f84d91b83673e8264d38fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8ba7a0f4f8294564ae672bdc7f90e1a7","IPY_MODEL_402d48cbdc744c7b9dd99e4cbb81b75b","IPY_MODEL_8dcb24dffdce4a8096a3bd6a477804d6"],"layout":"IPY_MODEL_c61d14b7cdf64632b009b079a569e9b2"}},"8ba7a0f4f8294564ae672bdc7f90e1a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9527ae784e64439c9bb0b18babb54357","placeholder":"","style":"IPY_MODEL_017663ef0da14ae3861eb693c9476e39","value":"tokenizer.json:100%"}},"402d48cbdc744c7b9dd99e4cbb81b75b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0860456d367f4480a42b932ab91500cc","max":711396,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27175400ced0452eb0d2df5cdf1dbaab","value":711396}},"8dcb24dffdce4a8096a3bd6a477804d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9148dd80b6cf4e8b96a640c69a4eb032","placeholder":"","style":"IPY_MODEL_34961aea41a04284a16cd848c74d38d5","value":"711k/711k[00:00&lt;00:00,23.4MB/s]"}},"c61d14b7cdf64632b009b079a569e9b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9527ae784e64439c9bb0b18babb54357":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"017663ef0da14ae3861eb693c9476e39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0860456d367f4480a42b932ab91500cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27175400ced0452eb0d2df5cdf1dbaab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9148dd80b6cf4e8b96a640c69a4eb032":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34961aea41a04284a16cd848c74d38d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1efe091191d04d0cbda363366ed51045":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0158ce533cd34bbcbc18874db8100db9","IPY_MODEL_d337922792c042b0ad31c5534167a6b3","IPY_MODEL_355eb604c996435cab9524bea9c36bbb"],"layout":"IPY_MODEL_33cc81b74ec14c44ad81e1b4372fc589"}},"0158ce533cd34bbcbc18874db8100db9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11ed69d1777049d5b6427bbe33484e42","placeholder":"","style":"IPY_MODEL_348c4d3b2ce04ed6ba1b62bbd49b54c6","value":"special_tokens_map.json:100%"}},"d337922792c042b0ad31c5534167a6b3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5366dceb652443b58795167452f649c0","max":695,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4b9490aca59842359a984f5920e709b7","value":695}},"355eb604c996435cab9524bea9c36bbb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a441256a8e4b459b86792b2779e6b200","placeholder":"","style":"IPY_MODEL_42cffad6bdab4f2ea9840068ee31c32e","value":"695/695[00:00&lt;00:00,56.2kB/s]"}},"33cc81b74ec14c44ad81e1b4372fc589":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11ed69d1777049d5b6427bbe33484e42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"348c4d3b2ce04ed6ba1b62bbd49b54c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5366dceb652443b58795167452f649c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b9490aca59842359a984f5920e709b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a441256a8e4b459b86792b2779e6b200":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42cffad6bdab4f2ea9840068ee31c32e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce1bf2dff62940d2adb3c5548f55e066":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_822ecdaba0a34e918f6243302b8d70f8","IPY_MODEL_96a3c38e37ec4ad7ad297774e49fc8a4","IPY_MODEL_96ed114f5584405ca3e1cb88f813a6b9"],"layout":"IPY_MODEL_a63bccc5fb5942878b518816b982d419"}},"822ecdaba0a34e918f6243302b8d70f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e1889ad6da14950a07b7af0a9ae52bf","placeholder":"","style":"IPY_MODEL_5c6ec71fc0134fdca945ce7d966c01f1","value":"1_Pooling/config.json:100%"}},"96a3c38e37ec4ad7ad297774e49fc8a4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_df78299c13124789aa6e86fcbbdfe724","max":297,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4cbd9563feba4fed8d51ac8386cce50d","value":297}},"96ed114f5584405ca3e1cb88f813a6b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5ae94e17843444bba1326d21835c878","placeholder":"","style":"IPY_MODEL_1cb8265c943a4c9b822893f78a74962a","value":"297/297[00:00&lt;00:00,14.4kB/s]"}},"a63bccc5fb5942878b518816b982d419":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e1889ad6da14950a07b7af0a9ae52bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c6ec71fc0134fdca945ce7d966c01f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df78299c13124789aa6e86fcbbdfe724":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cbd9563feba4fed8d51ac8386cce50d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5ae94e17843444bba1326d21835c878":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1cb8265c943a4c9b822893f78a74962a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}